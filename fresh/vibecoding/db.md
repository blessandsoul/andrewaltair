What in the world is vibe coding? Is it being super lazy and letting AI write all of your code for you? Or is it being a chill guy and manifesting B2B SAS? Well, today I'm going to break it down for you. I'm Matt. I work in developer relations at Replet. Uh, and vibe coding is basically a term for leaning on AI agents to write most of the code for the apps that you're trying to build. and it allows you to freeze your time up to be more of a manager or direct the outcome of the application as well as how it works and the functionality that it has. Now, vive coding was a term coined by Andre Carpathy who is a super early member at OpenAI and just a really famous guy and a thought leader in the AI ecosystem. We'd all known I think everyone in the AI community knew that something was up for the past few months seeing people build almost entirely with AI um and share their sort of experiences online. but he was the first one to put the term to the name. Since then it started getting associated with like this Rick Rubin meme where he's like you know sort of vibing to uh some music and after that it really blew up when Rick Rubin came out and not acknowledged the term vibe coding. I don't know how much coding Ripper Rubin does but he's even discussed it. I have no technical ability and I know nothing about music. But at the core, vibe coding just means using AI agents, using an editor that has some AI functionality to build apps almost entirely with natural language or even your voice. And what we've seen is that just about every 7 months, the uh amount of work that AI can do by itself is doubling. So a few years ago we had GitHub copilot and you could you know tab autocomplete uh finish a line then you know maybe six or seven months later you could write functions after that it was writing parts of files to features in apps and now we're at the point where these agents can write entire applications and this is actually been measured and seems to be following a pretty reliable trajectory. So at its core, vibe coding is just using AI to write code. But here's the thing, it's still really hard to build apps and that's because of the experience of developing applications. You still have to configure databases or add authentication. And there are all these security considerations, right? You don't want to leak your API keys. You don't want to get uh spammed or you want to make sure your application is secure and that there's nothing to worry about. And then even after you've considered all of that, how do you take what you've built and go from what lives on your computer to something that's live on the internet that you can share with other people? Now I work at Replet and we actually address most of these issues. So the cool thing about Replet is it's a browser native environment. You go to replet.com, you don't have to install anything, don't have to configure anything. We have all the tools available for you. Agent or autonomous AI native building system can configure your entire environment and even write the code for you. So, it'll do the vibe coding uh while you sit back and relax. From there, you can do things like add databases, add object storage, store your secrets in a secure environment that you don't have to worry about being exposed. And so, Replet's capable of doing all the hard stuff, doing the heavy lifting for you. And we cover the platform, most of the services that are roadblocks to actually deploying your application. And so, vibe coding at its core is the ability to write code, build apps almost entirely with AI. Replet is a platform that allows you to vibe code, but also provides a ton of useful services to make vibe coding in your life a whole lot easier. So, it's clear that everyone today is a builder, and that's only going to change for the better in the future. You're only going to be able to build even cooler stuff as AI gets better. So, you should check out Replet. You should check out platforms that allow you to build as much possible and share it in a simple, seamless way. But again, I'm Matt. This has been what vibe coding is. In my next video, I'll give you a gentle introduction to how you can start vibe coding. Until next time, peace.

I learned how to vibe code for you. So, here's the cliffnotes version to save you the hundreds, actually probably at this point thousands of hours I have spent watching YouTube tutorials, taking courses, but honestly, mostly just like trial and error as I'm developing my own applications through vibe coding. Vibe coding is seriously a gamecher and has fundamentally changed the way that I code and develop apps. Which is why in this video I'm going to be focusing on the fundamentals, the frameworks and the principles of good vibe coding. Then I'll also teach you how to apply these principles of vibe coding with any tool. As per usual, it is not enough just to listen to me talk about stuff. So throughout this video, there'll be little assessments. And if you can answer these questions, then congratulations. You would be educated on vibe coding fundamentals. Now, without further ado, let's get going. A portion of this video is sponsored by Brilliant. All right, here's the outline of today's video. First, I'm going to define vibe coding. Then we're going to be talking about the principles of good vibe coding. I'll then show you some examples of vibe coding in action using Replet Windsurf. Then finally, I'll end with some very practical tips to help you along your vibe coding journey and to make sure that you don't end up as one of these people from X and Reddit who really up. I do not want that for you. So, please pay attention until the end. Let's now define vibe coding. I'm sure many of you have heard the term vibe coding a lot of times by now. And this is a term that was coined by Andre Kaparthy who among many of his achievements is one of the founding members of OpenAI. On February 3rd, 2025, he made a post on X that says, "There's a new kind of coding I call vibe coding where you fully give into the vibes. Embrace exponentials and forget that the code even exists." It's possible because the LMS's, for example, Cursor Composer with Sonnet are getting too good. You basically just tell the LM what it is that you want to build and it would just go ahead and build it for you and some people literally just speak to it like talk to it. Also, I just talked to Composer with super whispers. I barely even touched the keyboard. For example, you can just prompt it with something like create a simple React web app called Daily Vibes. Users can select a mood from a list of emojis. Optionally, write a short note and submit it. Below, show a list of past mood entries with the date and a note. And yeah, that's it. Give it to the LM and it generates the code for you. And voila, that's what you get. Seems very, very simple. Crazy, right? You can see how it fundamentally changes the way that you code and and build things. But with that being said though, it's not like black magic and vibe coding will magically just work for everything. There are still principles and order in this chaos in how it is you ask it to build these things. So without further ado, let's actually cover these principles. The best course that I found that covers the principles, the fundamentals of vibe coding is a course called Vibe Coding 101 with Replet. It's a nice little free course that's created by Replet, which is a platform for vibe coding apps in collaboration with deep learning AI. The course explains that there are five fundamental skills in vibe coding, which are thinking, frameworks, checkpoints, debugging, and context. You need to thoroughly think through exactly what it is that you want to build and then communicate that with the AI. What we mean by think thoroughly is actually four different levels of thinking. Say, for example, you want to program a computer to play competitive chess. The first two levels of thinking are probably really obvious and it's just like very intuitive to you. Logical thinking is just what is the game and in this case the game is chess. The next level analytical thinking is asking the question how do I play this game? What is the main objective the goal of the game? Now the third level is computational thinking. You need to figure out how to fit the logic of this game into a complicated set of problems and configurations on the chessboard. You also need to think about how do you enforce these rules. And finally at the top level of thinking is procedural thinking. This is when you ask the question how do I excel in this game? Not only do you want to play this game, you want to play it well. So, you need to think about what are some strategies that you can use. What are the boundaries that you can push so that you're able to program your computer to be able to do well at the game. Then, of course, you need to translate this natural language that we described and communicate that to the AI to build. Now, for whatever it is that you're trying to build, a game, a web app, whatever, you also need to go through these four levels of thinking to truly properly define what it is that you want to build. Honestly, this is where most vibe coders have the most opportunity for improvement. Because oftent times because you're using natural language just to describe what you want to do, you don't really actually think through what it is that you want to build, what it is that you want your final product to look like. And that's actually kind of unfair because if you don't even think through exactly what it is that you want, how do you expect the AI to be able to figure out what it is that you want built? And actually, the best way to make sure that you go through each of these levels of thinking and communicate it clearly to the AI is to create something called a PRD, which is a product requirements document. This is an actual PRD that we defined with one of our clients. It is an AI powered personalized nutrition plan for diabetes. Level one of thinking which is logical thinking defining what it is that we want to build. So this is as part of the project overview. We wrote that the goal of this project is to develop an AI powered system that creates personalized nutrition plans for individuals with diabetes. The system will take into account various health related factors such as medical analyses, weight, dietary habits, calorie consumption and more. The next level of thinking, the analytical thinking is encompassed by the skills section. So this is where you list out what it is that you need in order to build the thing that you want to build. In this case, we wrote Python, healthcare data processing, open AIS API, image processing for visual plans, and UI development. You can you can also go into more detail about this if you want if you're very if you're more particular about which specific packages you want to use, which kind of front end, which kind of backend that you want to use, but this is good enough to start. For computational thinking, I like to express this by having a key features section in the PRD. This is where we can clearly define and have a plan based upon what we want to show up in the application. Here we have it divided into milestone one and milestone 2. The first one is a generalized personalized nutrition plan engine that includes specific metrics like individual health metrics and socioeconomic factors. The level two is where we want to give more contextual customization specifically considering people's literacy and education levels and making the application adaptable um and more accessible to different types of people for example people with lower literacy. Now for procedural thinking the highest level of thinking thinking about how do we make this application the best that it can be this is exemplified throughout the PRD just by adding as much detail as possible. For example, defining exactly which factors like individual health metrics like medical analyses and dietary intake data and socioeconomic factors such as income location and local food availability as well as what types of contextual customization. But the best way to think about it is the more detail you can go into thinking about your target audience, who you want to be using your application and that experience that they should get and all the factors that go into it to make it the best experience possible. the clearer your vision is and the clearer the PRD is and the better results you will get from the AI. Also, just by the way, you don't need to come up with this PRD all by yourself. Um, I'm actually going to put like a prompt on screen right now. Feel free to take a screenshot of this. This prompt will work with you and ask you the right questions for you to be able to come up with a well-defined PRD to build your app. I highly recommend that you spend a significant amount of time at this section. It is always so much easier to have a clearer vision of what you want as opposed to build something, figure out that it's not exactly what you want, and then try to fix it halfway. The next principle of vibe coding is to know your frameworks, whatever it is that you want to build, chances are somebody has already built something like it or something very, very similar to what it is that you're trying to accomplish. And since AI is trained on all the pre-existing solutions that are already available, if you're able to direct the AI towards the correct framework for building what you want to build, you're going to have much better results than asking it to just try its best to come up with something from scratch. And the easiest way to do this in vibe coding is just to list out the frameworks or the packages that you want the AI to use to implement the solution that you want. You're kind of just like pointing it in the right direction. For example, for your web app, you can specify that you wanted to use a React backend and a CSS and HTML JavaScript front end and specifically maybe Tailwind CSS for the styling for this specific type of application. Or say that you want to be creating animations, you can specifically say please use 3.js which is a very popular package for creating animations. Okay, so the question you might be thinking right now is like Tina, but what if I don't know what is the best way of implementing this thing? No problem. You can actually ask AI to help you figure it out first. For example, if you want to implement a drag and drop UI, which is a very common thing to implement, you could say, could you help me come up with some React frameworks to implement drag and drop into this application and then implement it. What is actually the key thing here is to be open to learning about these different frameworks and how all of these components fit together. With vibe coding, it's not necessary for you to exactly know how to implement each of these things yourself, but it's still really important to have an understanding of the structure of what it is that you're trying to build. Like if you're making a web application, at the very minimum, you should be aware of what a front end is, what a backend is, how the front end and backend communicate with each other, and what are certain frameworks that are very popular or commonly used for the front end and the back end. Think about it as building and developing and learning with the AI at the same time. This will make you a much better vibe coder in the long run. The next principle of vibe coding is to always have checkpoints and version control. Things will break. That is a fact. You do not want to end up like this guy, for example, who lost all of his work because he did not know about version control. It is a cautionary tale. He posted on X, "Today was the worst day ever. The project I had been working on for the last 2 weeks got corrupted and everything was lost. Just like that, my SAS was gone. Two weeks of hard work completely ruined. But I mean he is trying to stay positive here. He started from scratch. Blah blah blah. He's going to rebuild everything from cursor. So you know at least he's remaining positive. But anyways the point being that please always have version control. There are some software like replet for example that has pretty decent version control that's already built in. But for the majority of software and it's just like generally best practice is to learn how to use git and github which I'm actually going to give you a crash course on right now. If you already know how to use git and github consider this a quick little refresh. So first of all git is the version control software itself. While GitHub is a website that allows you to store your code, your repositories on the cloud so that you're able to have it, you know, saved somewhere else and also so that you can share it with other people. So, first you need to install git and you can do this by either downloading it from the website or you can go through your terminal/comand line or honestly you can just ask your AI code editor software whether that be like replic whatever and just directly say like please download git for me. Now assuming that you want to start a new project from scratch and you're in that current folder the command that you want to use is get init which is initializing git. Now let's say you start adding some things you might want to add a readme where you know you just start like vibe coding and now you have a bunch of files that are there. And if you use this command get status it will show that you have a lot of files that are unttracked. So in order to track these files you use the command git add. You can do get add like readme.md or whatever files that you want to start tracking. Or you can just do get add with a dot. The dot means just track everything. But you're not done with just adding these files and tracking these files. When you actually want to save a certain version of it, you use the command git commit. This is where you would explicitly commit the changes that you made to the files. And you can also type a message that explains what you changed in the codebase or otherwise known as the repository. For example, your first commit could be git commit-m with initial commit as the comment. And that's it. Actually, if you just do this, you would be tracking your changes, saving your changes by committing it. And you just keep on doing that. And if you ever want to look at the changes that you made, you can use a command called get log. And if you want to roll back a commit, then it's git reset. Okay. So after you made a bunch of changes, did all your things, and maybe you want to share your code now on GitHub. You can go to github.com, create a new repository, and initiate it. Copy the remote URL, then use the command get remote at origin, and then the URL. This will link your local repo that's being saved on your computer to GitHub. Then you might want to rename your branch, which is the current repository version that you're working with and call it main. So you can do git branch- m main. Then finally, you can push everything from your local repository onto GitHub with the command git push- origin main. There are obviously like a lot of other little nuances and commands and like things like that um specifics that you can go into a lot more detail about, but just knowing what I explained to you that entire workflow, that should be enough for you to have a good understanding of what version control is supposed to look like and what the flow is supposed to look like. And even though I did cover the exact commands that you should be inputting using an AI code editor, you actually don't need to know these exact commands. Like as long as you know what that structure is, you can just directly ask the AI using natural language. like you can just say um use git to commit these changes, push it to GitHub on this branch, roll back the previous version, merge everything together. I hope that makes sense. Overall, I hope you can also see that the key to vibe coding is to understand these like highle structures, these highle components and the flows of things so that you're able to direct the AI in the implementation. Implementation is where AI excels at. The next important skill of vibe coding is debugging. Whatever it is that you're building is going to go wrong. It's just a matter of when it's going to go wrong and how it's going to go wrong. Which is why debugging and fixing the thing is just as important as the actual building itself. This is a skill that is drilled into engineers with many many years of training. But for many vibe coders though, especially those who don't have an engineering or coding background, debugging might be something that they don't actually have a lot of experience in. And it's very important to learn this skill. The best type of debugging is very methodical and thorough. First, you need to identify where the problem is and what the problem is. then you need to apply different solutions to try to fix the problem. Sounds super simple, right? But do not underestimate the art of debugging. In the case of vibe coding, when you realize that something doesn't work, um I actually find that the best way is to just point it out to the AI and then let the AI come up with the solutions to fix it itself. For example, I recently did this live stream where I was building this application and then it kept on coming up with an error. I basically just copy pasted the error message and went like there is an error and the AI responded with like oh let me try to fix it. and then it comes up with like different solutions to try to fix the problem. And really all you have to do often times is just to accept the changes and if it still doesn't work it might just go through like a lot of cycles of this. Just got to be patient and just you know keep pointing it out letting it do its thing and often times it resolves itself but in the off chance that it doesn't resolve itself easily. It is really really helpful to have a basic understanding of what you're building. Like for example, I kept on getting the same error over and over again. But since I understand file structures and how the files are working with each other, I was able to point out which file was probably causing the problem and which section was probably causing the problem and the AI was able to go and fix it. Another example was when I got this overlapping UI component which I didn't like. I was like this thing is overlapping. I sent it to the AI and then it like made some weird changes and the whole thing just disappeared. And then I was very patient and was more specific about exactly what it is that I wanted. And looking at the code, I could tell that it was just statically trying to input like a certain dimension so that depending on the orientation of the website, sometimes it would overlap and sometimes it wouldn't. And then I just pointed out that I needed to be dynamic so that it's not overlapping at any point. And then fortunately, it was then able to fix it. And finally, the last principle of vibe coding is to provide context. The general rule of thumb is that the more context, as in the more information and detail that you can provide to your AI, to your LM, the better the results are going to be. And context can come in a lot of different forms. It could be that the original prompt or the PRD that you're inputting has a lot of details in it. You can even provide it with like mockups of what exactly you want it to look like. Or you can be providing it with examples or extra data that can help it build the application. Details about your app, your environment, your preferences, as well as errors. Instead of just saying this thing doesn't work, you can actually copy paste the full error message and a screenshot of what exactly doesn't work and provide that to the AI. Okay, so here's a little pneummonic that can help you potentially remember these principles of vibe coding better. The friendly cat dances constantly thinking frameworks, checkpoints, debugging, and context, which immediately comes in handy for you now because here's also your little assessment, which I'm going to put on screen right now. Please answer these questions and put them in the comments to make sure that you're following along with the things I am talking about. I'm now going to show you some examples of vibe coding starting with Replet. Replet is a platform where you can use AI to vibe code different applications and deploy them really really quickly all on the cloud. It is super beginner friendly. All you have to do is log on to Replet and they have some free credits that you can get started with. Let's start off with the PRD for a very simple app that displays SEO metatags for any website that is inputed. Okay, so to get started, the first thing I'm going to do is actually use chatgbt to help me really think about what I want this application to look like and generate a PRD for it. And I'm going to use this prompt over here, which is a variation of the prompt that I showed you guys earlier. And I'll also link an example PRD for chatt. So it just says, help me to make a PRD for an MVP app. I'm looking to vibe code. So, an interactive app that displays the SEO metatags for any website in an interactive visual way to check that they're properly implemented. The app should fetch the HTML for a site, then provide feedback and SEO tags in accordance with best practices for SEO optimization. The app should give Google and social media previews. And then thinking through these questions, what is this app? How do I use the app? What are the patterns behind the app? And how do I make the app the most useful for the target audience? And including a PRD example here. And it helps us generate this. So, SEO tag, visual inspector, MVP, PRD, project overview, and it shows all of the key features that are here. So, input URL field, HTML fetching and parsing, SEO tag extraction, and visual feedback previews. And there's also a nice to have section. All of this looks pretty good. I do want to have a key feature of actually displaying the total score out of 100. I also do want to get rid of these nice to have haves over here cuz it's always best to start off with the very very key features and then add on to that. So I'm going to ask it to refine it with for key features. Could you include a total score out of 100? Also remove nice to haves. Great. So visual feedback is over here. Awesome. So this looks pretty good to me. So, I'm going to write is could you make this into a prompt uh to build an app using replet? So, that's what we're going to use. Great. Wonderful. And on top of this, I'm going to say generate a image mockup or inspo. I'm going to download this. Here is a replet. And what I'm going to do is just copy paste the prompt from chatbt and also link the inspo and click start building. All right, it's going to be called SEO Tag Scout and it's asking me if I want these like additional things that are here and I'm just going to say no because we can add these additional features later. So, we can approve and get started. As it's generating, you can see that it's literally designing the visuals and it's also populating the files over here as well. So, for Replet, it already does have pretty good um version control. You can roll back pretty easily here. Although for best practices, you still really do want to be using Git at some point. While it's finishing up building everything over here, what I really recommend that you do is you can go over here and actually add an assistant and use the assistant and ask, could you explain to me the file structure in this project? You don't have to do this, but it's one of those things where if you're learning about the frameworks that are being used while you're vibe coding, this is going to significantly improve your skills as a vibe coder because you're going to be able to understand what's actually happening and how the files are going to be interacting with each other. We can see over here on the client side under client, you have the main React application code in the source. So, client source and you can see where the UI components are as well. And on the server side, it tells you where the main service entry points are like index.ts. And here's the code for that. And then roots and things like that as well. Just understanding the files over here and how they're interacting with each other to produce this completed app is already going to give you a huge leg up. And if you really want to dig into like some of the actual code, you can always rightclick over here and then you can say like explain with assistant for example. This is very very optional, but it is a really really great way for you to learn um what the code is actually doing if you're interested. All right, it looks like our app is now finished. Let's actually test this out. So, let's try ww.lonely octopus.com. Check. Uhoh, that didn't work. So, what I'm going to do is there is an error like a true vibe coder. We're going to hope that it fixes itself. Okay, let's try testing it out again. Lonely octopus.com. And cool, it seems to be showing something. the title, shorter than recommended, meta description, blah blah blah, all of these things. And we can see that here's the Google preview, here's the social media preview, Twitter card previews, and raw data tags. Okay, so I just want to make sure that the like number actually changes depending on the website. So let's try something else like the website called the useless website.com. Okay, so it's also still showing 86. What about this other website? Okay. All right. So the number is changing depending on what it is. It's like this is not visually appealing. Make it colorful. Yeah, make it colorful. I also don't like how the raw data tags are here, but it's not specifically specifying like what the title is sort of the recommend like what is the actual title. Like I want that to be showcased and I'm going to do that in the next round of edits here. Another key thing to remember is that it's best to when you're pointing something out, like something that you want to be changed, doing it one at a time as opposed to like a laundry list of things that you want to change cuz that could potentially confuse the AI. Oh, cool. I guess it did that already without me saying anything. Oh, and it's like showing little icons. So, that's nice. Okay, let's try this again. lonely octopus.com. Okay, I like that. This is much much better. Another thing that you can do over here is that you can actually click here and then there is a dev URL that you can directly look at from other devices as well. So all you have to do is scan the QR code. So you can actually see what it's like on other devices too. So if I were to type lonely octopus.com, you can see what that experience looks like on mobile as well. So this is a example of what it would look like to be web coding using Replet. And once you're done, you can take this and deploy it when you want to. But if you do want to create something that is more complex and that's also more scalable, you will at some point want to migrate to a AI code editor, something like Windsor for cursor. So I'm actually just going to show you what that is like um using Windinserve for example. First of all, regardless of which of these tools that you're using, the principles that we just talked about for vibe coding, like the skill set itself is pretty much the same. So don't worry about that. It's more the fact that after you get through the beginner stages, most people will want to switch over to AI coding editor like cursor and windsurf because it's more robust, has more functionalities, and also allows for greater scalability. Of course, with these types of things, there's always a trade-off. Like with Replet, it is a lot faster, really easy to use. Everything is based on the cloud. So, you don't really have to deal with setting up your environment and the deployment process. While for cursor and windsurf, there are a lot more functionalities that are available. These code editors are built for like full scale development. So you're pretty much able to do any type of development and be able to tweak things and fine-tune things to the exact way that you want it to look. Of course, the downside is that there is a higher learning curve. You need to learn how to set up your environments properly, how to debug issues with your environment. A lot of issues come because of not setting up your environment correctly. You also need to learn how to deploy things, how to monitor things over time. So this is the wind surf environment and over here is cascade where you can type in what you want the app to build. In this case we're using cloud 3.7 sonnet as the model. So I'm actually going to put in the exact same prompt and then also the image as well on winds. This is going to be a local development environment. So it's going to start off by setting up a bunch of things locally. You can see that the files are populating themselves over here as well. All right. So this is running a terminal command and we can accept this. It's you can disable and the asking and you can just let it auto run but I have trust issues cuz it's on my local environment instead of like rep play where it's in its like own isolated thing on the web. So I do like want to make sure that I am accepting things and not doing random things to my local environment. So I'm just going to click accept to all of these. You can see that it also takes a little bit longer cuz it's setting up all these environments and selling all these packages and stuff. Um, all things that don't need to be done if you're using Replet. Okay, cool. It looks like it has something done. It says, "Feel free to try it on the browser preview I've opened for you." Open the browser preview. I don't see the browser preview. Could you open it for me? Okay. Open preview. Cool. We see that it has some of these very similar elements here. www.lonely Lonely octopus.com for example check. Oops. Need to adding an https. Okay, this actually looks way better than replet's first version. I got to say it actually looks really really similar to the inspo that we provided. It like here's the inspo that we provided and here's the actual thing. It looks really similar, right? Looks pretty good. So SEO tag analysis. Yeah, this looks pretty good to me. Let's try something else. maze.toys/mazes/min/aily. It's just like a random website. Okay. SEO tag is 25. So the numbers are actually different um between Replet and Windfs. So that's interesting. Something I probably want to dig into asking like how it's calculating these SEO tags. But overall it looks like it's working pretty well. And I quite like this. So I'm going to ask it to change though. To improve on this a little bit, I'm going to say edit a screenshot here and be like make it so that you don't need to type https before the URL. Also, copy paste is not enabled. Let's open a preview again. So, try this again. www.lonely octopus.com. We also do need to center this later. And it still doesn't work. So, I'm just going to write still doesn't work. Let's try again. lonely octopus.com. Okay, cool. So, that works now. Um, obviously there's like other things that we want to fiddle around with a little bit like things that are not centered. Might want to change these colors a little bit, but I hope this gives you a good idea for how it is that you can start building using windsurf as the experience. And so, in this case, you also definitely do want to start using git and github as well. So what you can do is be like initiate git for version control and just type that in. Accepting everything here and then git is going to be initialized. Everything here turned green which means that it's unttracked. It asked do you want to get add everything? We can accept get add everything and it's asking us if we want to commit as well as our initial commit. So we can accept we can get commit to. So great now everything is being tracked as version control. And when you're ready, you can also get push and you can actually see everything now on GitHub. But regardless of what you use, remember the principles that we went through for vibe coding. Do keep those in mind and apply them regardless of what kind of tools that you're using. I'm going to put on screen now a little quiz. So please type the answers in the comment section. And now let's go on to our final section where I'm going to give you some more tips and tricks and frameworks and mindsets that will help you along your Vibe coding journey. The first one is very much a mindset. If you're already an engineer, you know, you probably already think this way. But if you're someone who maybe doesn't come from more of a technical background, always think about starting small and working your way up. In other words, whatever it is that you're creating, always think about it as the minimal viable product, which is what are the minimum amount of features that you can put into your application for it to function. After you get the thing to actually work, then you can iterate and put on like additional features and functionalities on top of that. This is the correct vibe coding mindset as opposed to you coming up with like the most lavish, you know, thing with all the details that you can possibly think of and like a million different features. No, no, no, no. I can already think of all the errors and issues that you're going to get from that and then just you like ripping out your hair because you can't figure out what's going wrong. Always start with the minimal viable product and then iterate on top of it. Get the thing to work first. Next up is a framework that's also from the vibe coding 101 course, which I think is really, really helpful. It shows that when you're developing or building an app, when you're vibe coding, there's really only two modes that you're in. You're either implementing a new feature or you're debugging errors. When you're implementing a new feature, what you want to remember is to provide context relevant to the new features. Mention frameworks, provide documentations with explicit details, etc., and then making incremental changes and doing the checkpoints and and version control, etc. And when you're in debugging errors mode, what you want to keep in mind is firstly figuring out how things work. Do you have a good understanding of the structure of your project itself? if you don't, you know, ask AI and and actually figure that out because it's going to be very helpful to figure out what is actually going wrong in your application. And when you figure out what's wrong, think about how to get that information to the LM to get unstuck. And this is where the final principle, context, is helpful. Just try to provide as much context and information as possible to guide your LLM to fix to fix the problem. Give it like screenshots of what's wrong. Give it the error message, point it towards the right file to be looking into. I really love this framework. So take a screenshot or something and whenever you're getting frustrated or not know what you're supposed to do, just try to remember which mode that you're in and what you should be doing in which mode. Final tip that is a little bit more advanced and these are writing rules or documentation. This is kind of like a system prompt that you're giving to your coding agent. And this is where you can list out like certain things that you wanted to do or to not do. For example, some of the best practices that you probably want to put in your rules include limit code changes to the minimum when implementing a new feature or fixing something. This is because AI sometimes has this tendency of like changing a lot of different files um unnecessarily to fix like a very small thing and then it could potentially break other issues. Rate limit all API endpoints. This is just to make sure that you're not like calling an API and incurring like multiple times and incurring a lot of cost. Enable capture on all authors and signup pages. So for security reasons and yeah there are a lot of other rules that you can put into this file. You can also find online like people have written these rules that are specific to like certain types of apps or certain languages that you're using as well that you can put into your rule file as well. And you can take this rule file and give it to replet where cursor ruins surf too. Especially if you're someone who doesn't come from an engineering background or like a development background, I really recommend that you actually look into the rules that are specific for ensuring like safety and security in your apps. Like putting it in your at least like learn things about like API keys and why it is that you shouldn't be exposing your API keys. And while you're learning these, also put your rules into your rules file so you're reminding your AI to be abiding by best security practices as well so you don't get hacked. All right, there is honestly like a lot more that I can go into detail about. Like for example, like having styling documents that you can reference, how you should be refactoring your code, using something like MCP servers. if you're building something like AI agents and you want to give your AI agents like more tools and functionalities. There's just like a lot which I don't have time to cover in this video right now. But please do let me know in the comments if you want me to make a follow-up video where I will go more in detail about exactly how it is that you should be vi coding and giving you more specific advanced examples for AI code editors like windsurf or cursor as well. But for now we have come to the end of this video. I really hope this vibe coding fundamentals video is helpful for you to get started um doing it correctly like vibe coding with best practices in mind. And as promised, here is the final little assessment which do answer these questions and put in the comments to make sure that you retain the information that I just covered. If you're watching this video and interested in vibe coding, chances are you're probably also interested in learning STEM subjects. So, if you are interested in learning STEM subjects, I highly recommend that you check out Brilliant, the sponsor of this portion of the video. Brilliant is a STEM learning platform that helps you get smarter every day with thousands of interactive lessons in math, science, programming, data analysis, and AI. What I love about Brilliant is that it helps you build critical thinking skills and deep understanding of subjects instead of just memorizing things. Brilliant incorporates little quizzes, analogies, and just little dopamine hits that really help a lot when you're getting bored or discouraged. It's shown to be six times more effective than just watching video content. They also have a great mobile app so you can actually dig into a quick little session and learn something new when you have a couple minutes instead of just mindless scrolling. Brilliance programming courses are some of my favorite courses. They help you build a foundation of coding and teaches you how to think like an engineer, a skill that is still crucial in the age of AI and the age of vibe coding. Speaking of which, they also have great AI courses, too, that can help you gain a deep understanding of how AI models work and their applications. Brilliant courses are super high quality and taught by award-winning teams of teachers, researchers, and professionals from Stanford, MIT, Caltech, Microsoft, Google, and more. To try everything that Brilliant has to offer for free, you can visit brilliant.org/tina or just scan the QR code on screen. Or you can also just click the link in the description. If you use my link, you also get a 20% off the annual subscription. Thank you so much, Brilliant, for sponsoring this portion of the video. Now, back to the video. Thank you so much for watching this video and happy vibe coding. I'll see you guys in the next video. We're live stream.

You can be a domain expert with AI with the power of like asking flawed things, right? And the other thing I want to talk about is like what it means to vibe code and all people see on Twitter are like the demos that they're like, "Oh, look at this thing I built in 15 minutes. It works. It does all this amazing stuff, right? They don't see the failure and the learning." A lot of people ask like what makes a successful vibe coder like how do I get good at this thing? I think courage. the courage to fail, the courage to start over, the courage to again feel like, oh, I just spent two hours and I didn't actually create anything that worked. But you know what? I'm gonna roll up my sleeves and figure out how to do it the right way and I'm going to try again. When agent's building, what you'll notice is that it's like editing these files, debugging on its own. And so when it built that first app, we were talking about like prompting best practices, but it actually like made some edits. It took a screenshot of our app to make sure things were working properly. um it'll run test commands and scripts to make sure that it's building the way it should be building. Maybe we'll see some of that in a second. And that's fundamentally different from how a lot of other tools work. All right, welcome everyone. My guest today is Matt Palmer, head of developer relations at Replet. Uh Matt is a VIP coding expert and a real engineer. And today we are I'm going to ask him to build an app to help busy parents find kid-friendly places nearby like playgrounds, hikes, and more. something I could personally use every weekend. Uh, and we're going to do this step by step to teach you how to build this app yourself. So, welcome, Matt. Thank you for the introduction, Peter. Really grateful to be here. A little nervous anytime anybody introduces me as an expert and a real engineer, but let's uh hopefully we'll have some fun. We'll build something cool. We'll build something useful and learn a bit along the way. Um, so we can just yeah, we can jump right into it. I'll share uh my screen here and uh we'll get started. Um, one second. Perfect. Uh so um today the goal is to build a family activity finder using Replet. We're going to talk about best practices in prompting, best practices in vibe coding, what makes a good vibe coder. Um and we're going to talk a little bit about the landscape of the tools out there because I know it can be confusing as well. Um most importantly, hopefully we'll have have some fun and we'll build something cool. Uh so we're going to talk a little bit about the prompt and then just get started building in Replet. The way I like to structure these demos, because as most of you probably know, AI takes a little while to write code, um, is that I like to jump right into it and, uh, talk about building the prompts and then take a step back while we're building to kind of discuss the tool, discuss the landscape, and some of those other conceptual things I mentioned. Um, so, you know, one of the ways I like to approach building things like this, uh, is to think a little bit like a PM. Let's think about like the problem that we're solving. Let's think about what we want the solution to look like. Let's start to think about this like problem space, right? And so when I think about like finding activities, I really want kind of like a map first interface. I want something that looks maybe a little bit like this. Something like a Google Maps or an Airbnb search experience. Um, and you know, some of the skills we're going to talk through when we build this are prompting, processing, analyzing external data because these places that we want to find on our map, they have to come from somewhere, right? Uh, debugging. Uh, we'll talk a lot more about that as we go on. Um, but if I think about what I want to build, it looks probably something like this. And if I start to break down that problem, might look like, hey, I want an interactive map interface that shows these locations. I want filters or, you know, some other location based features that show nearby activities. Uh, and then maybe I want to get to the point where I have a favorite system with like user login so I can log in, save things, or mark them as done. Um, and most importantly, we want this to be mobile friendly because, you know, parents are going to be on the go using this with one hand, right? Um, and so, you know, when we start to think about these things, this can be daunting. Um, it can be intimidating to think, well, where do I get this data from? How do I figure out if that even exists? And, you know, here's where I'd like to add a plug for using AI tools, using web search, using tools that have access to web search. You know, maybe open up claude and say, help me understand this space. What uh open source data exists that might be able to give me this location uh these locations, right? And basically what I did was just that and I found out about this thing called open street map. So if you're unfamiliar Open Street Map big open source data set lets you query basically all of these different types of data. And so like here are some examples. If we were going to call the Open Street Map API, this is like what that data would look like. Now how did I find this? Again, just doing like some search, finding some docs, etc. And and this really is domain specific knowledge, right? Unless you're a maps expert, you might not know about these things. But what I want the the point I really want to elaborate on is that you can be a domain expert with AI with the power of like asking clawed things, right? And the power of AI is in product like understanding these domains. So hopefully what we're going to do today is going to show you that, right? And we're going to walk through this example. So crafting kind of like my prompt on replet. I'm going to say, "Hey, help me create this simple minimalist maps application to visualize our kid-friendly places. This is some of the other research I'm talking about. I looked up some framework." So I prompted Claude, "Hey, what are some good maps frameworks? Let's use leap leaflet for the map visualization and open street uh map for that data." What I did was in this prompt box I just pasted in that uh mockup that I created and then I said hey like let's use these open street map data types and again I found these by asking claude. So I said I've attached a mockup and some docs. Now you'll notice that when I paste this link that we pasted in here it pulled it into our sort of like scraping modal here. I could take a screenshot of that or get the text content. So now what I'm doing is I'm saying okay here's what I want my app to look like. here are some actual like documentation on the way that this uh framework that I found online works. And then what I could also do is come in and say, "Oh, well, I was on this Overpass API site. You know, I don't work with APIs. Maybe this is a little too technical for me, but like this is a quick start for 60 seconds for like a developer." And you can think about replet agent replet as a junior developer. So, if this is just like a snippet of code that we could run, well, I bet if I give agent this sample of request and response data, that's a little too long. We'll trim that up a little bit. We'll actually only just take most of this. Maybe if I give agent this request and response data, right, it'll help me um build out that application. And so, um, what we're starting to do here is, uh, build the context for our model that we're going to use in this prompt. So, now we're going to click start building. We're going to talk about what's going on. We're going to talk about why we're doing all this, right? And the context of of what we're building here. Um, but the first thing that agent is going to do here with our prompt is come up with a plan. So, it's going to say, "Hey, based on all this input you gave me, let me propose a plan for what I want to build for you." Um, and that's the first step on Replet. and then we'll move into the actual building. Yeah, I think that's really important. I usually uh when I you know do the co-pilot PM stage with cloud or you know even with replet itself I ask you to give me the simplest text stack possible and also maybe use like free APIs like try to keep that as simple as possible so I don't have to pay for anything you know 100% yeah we're not trying to get anyone to anyone to pay anymore these tools can uh you know start to add up on us right but um what we're what we're doing here you know we'll note that based on the original kind of spec What I was talking about here is is we selected some subset of these features and we said okay like how can we make this as simple as possible to get to something that works and then start to build on that and that's going to be a theme throughout this uh this tutorial. But the other thing I want to call out is that the first thing agent's going to do is design a little visual preview for us. Um, often when we build with maps, it doesn't actually show us um like the the map because that's rendered with uh React. This is just um HTML and CSS. But this definitely conceptualizes like what we want to build and it looks like it's going to be on track. Um so the first thing agent does is build this v visual preview and then it's going to start writing code for our app. Now this um what you're seeing in front of us is the replet workspace. I think I'd be remiss if I didn't talk a little bit about what this is or why it's different from some other tools out there. So, when you go to replet.com, kind of taking a step back, you're getting an entire code editor and development environment. Now, we're actually taking that and giving the environment to our agent, which is like our junior software developer to use. It has access to all those tools. But the really cool thing about this is that it runs entirely in the cloud. You don't have to install anything on your laptop. And what we'll see is that Replet has access to all these services and tools that it's going to integrate into your app in real time. So very powerful, you know, like agent is building out this app in the background. You see all these files starting to pop up as it starts to work on that prototype. Um it builds full stack applications. So we have a client and a server. What that means is that we're going to have a front end and a backend. And the back end will build APIs and then communicate with that front end. Um, and it's a really powerful architecture because it's sort of standardized and easy to understand even for someone who might be new to this. Um, but also we have this entire environment that's running in this like little window without installing anything. We'll get more into those advantages, I'm sure, as we keep going. And I think having the visual element streaming is also pretty unique to Replet. I I haven't really seen that anywhere else that I've tried. Yeah, it it makes it cool because you have to wait for a while for it to build everything, right? But it makes it you can kind of see what's happening. Exactly. And that was, you know, kind of what we were going for. You know, it's a little less uh impressive in this example because there isn't a preview of the map, but for other things where you're like designing something that's a bit more visual and simple um that doesn't have like embedded map elements, it can be really useful. Uh and so, you know, if we're talking about uh vibe coding, right, we kind of went to our prompt here to get to an MVP. Um and there are some prompting tips I like to share with folks. We won't, you know, we'll talk about some of these. Uh, and you're going to see all of these as we build through this app. Um, but what I've noticed when I'm teaching like, oh, you know, how to v vibe code or like how to build with these tools that a lot of people get kind of hung up on the experience of building and I think it's um, super common because a lot of the principles we're going to teach here actually are just principles of like software engineering or debugging or kind of like logical thinking. Um, and that's not intuitive for a lot of people and we take those for granted. I think a lot of people that have been building in the AI space for a while. So what we're going to see just to call out a couple of these as we start to build is that checkpointing is really important. It's kind of like version control for our app. And what we'll see here we actually have our preview done here is that agent creates these checkpoints. Right? So when we're building can actually go to a history. Agent is going to save off versions of this application for us as it's building. And the really cool thing is that this is just under like behind the scenes. This is just get, right? And so at any time we'll be able to go back to these checkpoints. And you can think about it kind of like playing a video game, right? Like if you get to a checkpoint, you don't have to worry about using your work. If something breaks, you don't have to worry about losing your work. If something breaks, you can go back to it. You can kind of like save your progress there. Um, and you know, that leads into debugging, which I think should largely rely on that checkpointing functionality. like if we get to something that works, we can start there and then, you know, add on new features, debugging along the way to figure out what's going wrong. Um, but as I talk through these, I kind of want to actually implement them in parallel for you. So, it looks like we have our map here. If I click on one of these, I mean, looks like real data. I don't think Coll just hallucinated this on us. Um, I think this is pulling from Open Street Map. But the first thing I always like to do is to check to make sure things are working because sometimes AI can hallucinate on us or like things might not work. Uh but we want to make sure that they do. So I can click on these places. I actually can't click on the search um uh box here. So that's something to note. If I try the filters, looks like the filters are working for me. Um and typically what I'll do here is I'll open the console. So the console shows us what's going on on the back end of our application. Now that can be a bit confusing because there's also uh the dev tools which some people refer to as a console multiple names and this shows us what's going on on the front end of our application right but what we're doing here is we're setting up our tools for debugging to check for messages or logs and what I noticed on the console is that we're getting IDs back and some data. So I think we're fetching these properly. Now, we won't get too hung up on design because what I want to focus on for this demo is building in features, but I think it's important to show you like how I would iterate on this application. So, what are the things I noticed here? Well, first, sorry, real quick. Which one which one is the browser compos? Is it? So, this this icon here is the dev tools. And the cool thing about Replet is that these every time we develop because it's in the cloud. You can think about with other tools you might build on local host, right? Um, here we're building in the cloud and so you have this live development URL, but that button I just clicked is the same thing as opening up your Chrome DevTools. We just provide a shortcut. And so you can look at this in the browser, which is what we're doing. The cool thing about this URL, I don't have my phone handy on me, but you could go to this URL and you'd be able to see this application in real time, right? So, one of the cool things about prototyping on Replet is if you have your co-workers sitting next to you and you want to try and build something and do it interactively with them, they can also look at this app. You can look at it on your phone. Um, and we provide some handy shortcuts for doing that in the browser as well. For example, you can resize the screen to see what things might look like on mobile obviously. Uh, we'll have to do some work to make this mobile friendly. Yeah, that's awesome because a lot of times I run into issues where it's working in a local host and not, you know, remotely and then or vice versa. So, I guess this avoids a lot of that. 100%. And that's the power of this kind of environment in the cloud. If you're more technical, you can think about it like a container. If you're less technical, just think about it like its own computer. Now, the cool thing about it being its own computer is that you can just click deploy and we're going to deploy this entire environment. So, if it runs on Replet, you can deploy it. That's really powerful. But I don't want to waste too much time here. Uh let's let's make some improvements to this map first. Um I don't uh let's say let's uh improve the icons. I'm a big emoji guy. Uh let's make them emojis in a circle with a blue outline. Uh for uh emojis basically for each um activity activity type. So that'll be the first thing. And then sometimes as I'm building, I like to also take note of things that I'll fix next. So for example, uh we want to fix the search box. Like that's a pretty big one, I think. Um, but off the bat, like I think the data is the hardest part um, of any app like this. So, fixing the search box, making this responsive, making it mobile friendly already. That looks like 10 times better. I already like this a little bit more. Um, search box. I don't really like this map theme. Like, this is a little bit busy for me. So, maybe map theme is something to think about in the future. Um, responsiveness, right? Responsiveness also means mobile friendliness. What is that? Uh what is that? Oh, it's playground that that that kid picture. Okay, the kind of it's a little creepy. Uh let's we'll change that. So, one of the things uh change emoji uh or playground to uh slide like the slide emoji. Yeah, we'll do that first because that's a little weird. Uh, and then we can start working through some of these other things. Um, but already we're starting to get to something pretty cool. And you know, from from where we were, uh, you can see we're getting some good progress here. Now, what does this directions do? I can see in the bottom left, what I'm going to do here to test this because I don't want to like, you know, reveal my address to everybody by clicking this and opening it on Google Maps is click it, open in a new tab. And you can see basically from that little preview, this would navigate to our direction. uh in Google Maps. So, we can be reasonably certain that that's that's working as I would expect. Now, we have our playground icon. Um so, another cool thing about um we use relief leaflet, right, which is uh our framework for this map. We could say use the cardo. It's kind of like a little hack because I've used this before. Light theme for a leaflet. Um and that's going to give us a bit more of a minimalist map theme here. Uh but what we have here is um our map. It's showing our locations. We can navigate to it quickly. So we're starting to get through our criteria, right, that we talked about. We can filter on these locations. Um search isn't quite working, but now we have a bit more of a minimalist uh view here. Um a lot better. It it does, right? And we're getting there. Uh but you know, if we tie this back to some of our um some of our prompting tips here, what am I doing? Well, I'm starting by uh we'll mark this up a little bit so it's a bit more clear to see. I'm starting by showing the AI what I want. So, I'm using images. I'm using code. I'm using snippets and sample data to really illustrate what we're trying to build. I'm keeping my prompts concise. We're keeping it simple. And we're walking through these solutions one by one. We're defining our outputs really precisely. We're considering some of those edge cases. Um and kind of throughout this whole process, we've been thinking like a PM and and an engineer. This actually I think vibe coding is harder in a lot of ways from just you know being told what to do and building something because we're figuring out what we're building as we go through these this exercise right like we're figuring out what this looks like. So now I'm going to say hey um the search isn't working. I can't click the search box. I'll test one more time. Yeah, still can't do it. But, you know, step by step, we're making a lot of really good incremental progress here. This already looks a lot cleaner um than it did before. Search box is set as disabled. Well, there's your there's your why it's not working. Yeah. And uh you know, that's kind of what that's what it's like to build with LLMs. And so, you know, we also asked, you know, we didn't do this in the demo, but we asked about tools, asked about frameworks, started to understand, you know, what we'd be building with, whether that's leaflet or open street map or these things that maybe we've never heard of before. Um, but we can actually unlock just by giving the right context that that uh thing about using like some light theme for leaflet, you can just search for leaflet and find online, right? Some documentation or something. Yeah, sure. Like if you do like leaflet themes. Yeah. like oh hey look we could actually okay this is not learn about the different themes that exist in leaflet got it so it's not just asking LLM sometimes it's literally just you know unpacking these frameworks unpacking these things that exist and then saying oh like well now that I know this thing exists I didn't know what I didn't know right and now I do and now I can ask AI to implement this thing for me um and you know I think the big the big thing here is that a lot of experimentation is necessary. Um, what we're doing is we're building on the frontier of what's possible, right? These are all brand new tools and one of the most fun parts about my job as an educator is that we're discovering the best ways to prompt LLM. We're discovering the types of things that we can build. Nobody knows really what's possible. And so, as practitioners, yourselves, as builders, you get to explore that and you get to build things that people didn't know were possible before. Um, and so let's see. Okay, looks like we have some search on our app now. So, yeah, it's coming along. Um, let's take a look. What were our criteria? Uh, we were saying we got our category filters, we have our map interface, we have um we can get directions with Google. So, we'll also consider this one like partially done. Now, let's talk about some of the things that make Replet separate from some of these other tools. Hopefully, you've already been able to see, right? On the back end, we have an API. This isn't just like a web app. That's just a client side app, just a front end. It's actually a full stack app with a front end and an API. Now, where this starts to get powerful is that Replet has added in a bunch of services that integrate directly into the platform rather than going out externally and adding in services. And that includes things like databases and off, right? So when I'm prompt agent here, I'm going to be able to add databases and off, but like nobody really cares what databases or off are. They care about what they allow you to do. And what they allow us to do is add users and store data for application. So in this next prompt, sorry. Uh let's quickly define O basically means log logging, right? That's basically what O means. Yeah. Yeah. Off like uh it'll be very clear, but like you know here you can see my profile icon in the top right. I think that's like the clearest way to show it. It's like what we're going to do is we're going to do that for our app. And so we're going to do it in in a way that uses Replet's infrastructure. So when we add o we're saying okay I just want to add users and login and because replet can add databases to your app it can store those users it can store that login and it can actually integrate it in a way that's completely bundled in our replet app which makes it a little bit simpler. Mhm. So now what we want to do, this is going to be a bit more of a complicated step, is I want to be able to save and um let's say mark uh locations as done for um my user. Add login. Uh we'll just you can just say add login or add off and we'll match that for you uh to my app and the ability to save locations. Um oh why don't we make it like uh favorites instead of done because you know I still might want to go back to it. Well so what I was thinking is we have favorites and then we have like visited right. So okay you have two different categories. Yeah. Yeah. This is like you know I need to learn some PM skills to define these things a little bit better. Let's uh so we'll clear that up. If it was confusing to you, it's probably confusing to agent. I want to be able to save favorites and mark my favored uh locations as visited. So, basically, this is like I go hiking a lot and this is what I want, right? Like I want to have a list of favorites, but then I want to know of those favorites which ones I've already done and maybe which ones I want to go back to again. Um, so yeah, we'll send that and we're going to observe what happens because I think this is going to be interesting and maybe um informative and then I'm going to talk a little bit more about how agent builds and we'll walk through some of these past chat messages um because there are some also important things to call out there. So what you'll see right if I open this up we're integrating with replet off and a database and so that database I showed you agent's going to create this database and attach it to our app. It's going to implement off and attach that to our app as well. And yeah, like uh I I normally stay away from this stuff because it's it's actually like a huge pain in the ass if it's not built into the platform to do this stuff. Like it can get totally stuck, you know, right? And then you're creating multiple accounts. Um you're pulling in external APIs. Uh you could be exposing sensitive information. The thing that we're really proud of and that we've been we recently released last week is uh some security scanning functionality which we'll talk about but also what we've always done is build these apps with a client and a server and then built the database in using best practices and what that means is that out of the box you get protected against things like SQL injection or like some malicious attacks on your database. Um the API calls are separated from the front end. So basically um we make it very difficult for like attackers to you know or or even people that just go and try to like mess around with your app to get information out because of the way that we build these apps. Um and that's also true of Yeah, exactly. And that's also true of like O for example because we're using Replet's authentication service. It's protected by um you know a bunch of our authentication infrastructure. Uh, and your app out of the box gets things like protection from DOS attacks and some of these other things because we're building with these sec this secure platform. Yeah. Because if people mess around with my app, I have not have no idea how to protect myself. I don't know any of the stuff. So, exactly. Exactly. And I have some blog posts about that as well, like what we do and everyone can feel free to read more about that. Um, but the other thing I want to call out is that when agent's building, what you'll notice is that it's like editing these files, debugging on its own. And so when it built that first app, we were talking about like prompting best practices, but it actually like made some edits. It took a screenshot of our app to make sure things were working properly. Um, it'll run test commands and scripts to make sure that it's building the way it should be building. Maybe we'll see some of that in a second. Um, and that's fundamentally different from how a lot of other tools work. Um, and I found when I'm building these apps, it makes the process a bit easier. Even if this run is a little bit longer, I can come back to the app with more certainty and know that it's running. And so often my flow is I'll be building something. We can talk about these and I'll keep an eye on our little fabicon up here. It might be tough to see in the stream, but it's purple right now. And it'll be green when agent's done done building this next step. Or you can just go on a hike, man, and like, you know, pull up rep on mobile and then This is true. If it's done. Yeah, I mean so I feel like you know a lot of people might say oh mobile you know that's great most mobile apps are kind of gimmicky you get the full functionality of replet on your phone and you can see the app that you're building you can see all the code I mean a lot of times if I'm going to an event I live in San Francisco which is why this map is of San Francisco I'll be like in the Whimo or in the lift or whatever like I need to finish this app you know I need to add more functionality I need to polish it up and it's like pretty good you know so maybe one day I can do my do my job out on a on a trail in Marin or something, you know. Yeah, that'll be amazing. Yeah, baby steps. Baby steps. Uh we'll get there. So, where are we on our kind of journey here? Um we have our map, we have our category filters, we have our some location based features, and now we're working on our favorite system. And then we might get to some mobile friendly design things. Um we're implementing our best practices and we're we're you know, uh learning a little bit about what it means to be a good vibe coder. And the other thing I want to talk about is like what it means to vibe code and what it means to use AI to generate outcomes. Now, if you're PM, if you're listening to this, if you've used Claude or Chad GBT, what you know is that the same prompt gets you different results. That's like a little disorienting and kind of scary because it means that sometimes you might get bad results and sometimes you might get good results. And so I have a normal distribution here. Like if you've taken statistics, all this means is that like this very oversimplified model, this probably isn't what the variance looks like. Our quality of outputs are probably on a spectrum. Like sometimes we might prompt agent, we might get something that's over here that's like really good. Sometimes we might get something that's like subpar. Sometimes we a majority of the time rather we might get something in the middle. And so what that means is that you know sometimes we might build apps, they might work really well. Sometimes they might not work really well. But there are things we can do to increase the likelihood and quality of the likelihood of success and the quality of the apps that we're building. And those are the prompting tips that I just talked about with you all. Right. Yeah. And so yes, this is an oversimplification, but nothing is perfect and you will get errors. And that's a big part of vibe coding. And sometimes like uh you know, you have initial prompt and they build something that's like doesn't actually work and it you can get stuck, right? And sometimes it's I won't talk about the details of this, but sometimes it's good to just start over again because like like I said, sometimes it's good and sometimes it's bad. Yeah, 100%. Right. If you find yourself in this in like a you're you're giving prompts, you're doing all of the things that we talked about and you still can't get it to work, sometimes you just got to start fresh and you know like actually right if we think about variance and what this means in terms of statistics, you know, we're too used to certainty, right? Everything we've built has been certain. Normally you open up a tool and it's like press button get result. That's not true with AI. And so the two things I like to tell people are don't be afraid to fail. And to your point, Peter, don't be afraid to start over. And so, you know, the secret, quote unquote, I was talking to SM engineers about this a couple weeks ago. The secret of being an engineer is just failing a lot, right? And nobody wants to see nobody wants to know about, you know, the hours you spend building something and breaking it and trying over again and looking like looking like an idiot. I say that because I do that all the time, right? Um, and all people see on Twitter are like the demos that they're like, "Oh, look at this thing I built in 15 minutes. It works. It does all this amazing stuff." Right. They don't see the failure and the learning experiences and all the other stuff. Yeah. People don't tweet like, "This is wild. I built this in 15 minutes after two hours of trial and error." They don't they don't tweet that. Doesn't Exactly. Exactly. And you know like this demo I've built similar demos and that's how I knew how to use certain features and I've built with replet before and that's how I knew to use replet off and that's really what I love about my job is that I do these things and then I say well now how do I go and show them to people in a way that you know they can kind of work around the mistakes or they can have shortcuts to building these things. Another another advanced tip, at least for me, is like after I get stuck in one of these like endless cycles, I ask AI like kind of like what what did we learn so far to avoid these mistakes? And then it tells me and I put that part of the prompt back into the initial prompt to start over again. So then do the same all over again. Yeah. No, that's a great one. Um, sorry, I just got distracted by the prompt here. I agree with that totally. Uh, we'll we'll talk through it. Um but I do use that with agent quite frequently. I think you know people forget they think they have to come up with all the things but you know you can ask AI what would you add next to this application? Help me understand what we just built. Help me understand how this thing works. Um exactly and and you can actually learn that way. That's you know a lot of people say um hey you know like all this AI no one's going to learn how to build anything anymore. Well, I can tell you personally, I've learned so much about web development just by watching agent work and like digging into what a client is and how it's structured. Dig digging into what a server is and what these things are, what a route is, how this app is structured in terms of React and whatnot. Like I got my background in data, so I wrote a lot of Python, but you know, AI has really taught me a lot about webdev and how to how to build front-end applications in Typescript. Um, so, uh, let's see what we got going on here. It looks like this is a sec. This is just a randomly generated string, so we don't have to worry too much about exposing that. Looks like agent might have done what we asked. I'm going to open this in a new tab. We'll go over here. We'll close this guy. Um, so this is our preview of our app. Now, what we have is a login button. Let's see what happens if I click login. So, this is going to say, hey, we'd like to access your replet account. There's my replet account. I'm going to click allow. And right when we say off, this is kind of like logging in with Google, right? So now I'm logged in and theoretically I my account now has access to the app. What's going on on the back end, right? We have O um I have a user and you all you know maybe Peter can edit out my email from what I just showed you. Okay. Okay. Uh we have a database. Um and in the database we have users. There's my email again. Yeah. Time time stamp. Don't worry. Yeah, I love emails. Uh but uh it looks like right we have um we have the tables that we would need sessions, favorites, places uh to store our data. And I'm walking through this because you know sometimes this can be a bit tricky to configure. Now do we have somewhere where we can favorite these places? I I don't actually think we do. Like I don't know where I would click favorite and it still says login save favorites. So, I guess what I kind of learned here is uh there's no place to favorite um a location and the app still still says log in to save favorites after I've logged in. However, right, still impressive. What we've done is we've laid the frown the groundwork rather for being able to save this in a relational database. And you know, again, relational databases are like kind of complicated. it can get kind of scary. But what I found with using AI is if you really start high level like hey what's the best data structure for my application you can ask agent that what are some like ways that we can build this app that would simplify the data structure or make it faster or make it easier to um interact with and then from there you say sorry yeah getting there getting the database and login working in one prompt is pretty amazing I mean I mean it took two prompts so you know I can't take all the credit but um yeah no I like I'm blown away um when I use this tool and you know that's the power of having these um integrated uh this integrated functionality in the app and something I kind of breeze through is that we also have secrets right and you know if you've ever used a N file or you've tried to use secrets locally or you actually accidentally push secrets to GitHub you know I did that early on in my engineering career um this can be really useful if you've ever saved secrets somewhere in your computer then forgot where they were like API keys or stuff. We have account secrets. So like I could pull in um any of my account secrets into this application, right? And um you know the power in that is that you can just enter in API keys. They pull through to your app. As you saw earlier, agent actually edited API keys and added one to my app. It created that random session secret for us. And so having all of the what you're starting to see is having all of these tools integrated into one experience um saves us time. We don't have to go to different providers. we don't have to like break our flow state. Uh and it makes things easier and helps prevent mistakes. Um for example, you know, one of the things we did here is like we made it impossible. So the session secret is not a real secret. It's a random string for our app. Um we're working on building in some uh like checks basically like so if you paste in an API key with agent, it actually should throw a warning. So I'm going to pass that to the team. Normally it alerts us that that uh that that would be an API key. So something's broken there. Um, yeah. You don't want you don't want the LM to remember your API keys. Yeah, exactly. So, we're forcing people kind of into best practices that way. Um, now, okay, we have our app says save my favorite places. I'm logged in. I can click my So, this is like I could see potentially my favorites. Um, see what happens when I click that. Did anything happen? Let's go over here. Nice. Um, so copy the page. Yeah, we're uh we're learning about what what works and what doesn't. So, um what I usually like to do is check the console like what happened. Um you can see we're making all these requests and I'd say I get a 404 on the favorites page. 404 is just not found, which is what we saw when we clicked um here. Yep. And you know, we can even add this context because I'm pretty sure that's the issue. Did you forget to add the page to the router? Should know what that means. And then, well, let's take a look. When I click favorite, what happens? Um, you can actually see post API favorites 2011. Like, sounds good to me. Um, when I click favorite, I can see a 2011 in the console. But um Oh, and we get visual feedback. It just took a second to come through there. Yeah, there you go. And I also don't think And now we have Mark visited as well. So um that's amazing. Yeah. Yeah. Yeah. So it took uh a few seconds for the um favorite to populate on the front end. Can you make it instant? Um so we'll go after these one at a time. We'll say this guy first and then we'll follow up with that. But this is getting much closer even if you know I care a lot about padding and spacing and UI and this this is driving me a little nuts right now but we'll get there. So let's test the mark visited functionality as well and see what happens. I click that um looks like it and and like po post just just to kind of explain to nonangle people post just means updating like updating some data in database right 100%. And you know I you again as as someone who's built with these tools I take that for granted but what what you will see just like if you're using a spreadsheet and you're learning formulas in a spreadsheet just like if you're learning a language um whether that's you know uh Latin or French or whatever or an actual programming language you'll start to understand oh a get request just means it's getting this thing. A post request just means we're sending information. A patch request means we're updating something. Um, and again, we see our little check mark icon come through there. So, it's again, it's a little delayed, but you kind of learn how to speak the language of of web development, of building with these things. So, yeah, it's all a learning experience, and I would just say don't let it intimidate you really. And and um, can you show us uh I know it's not fully complete yet, but can you show us how easy it is to deploy? 100%. Yeah. Yeah. So, the cool thing about deployments is that when you click deploy, it's just a snapshot of this environment. Currently, one one thing a lot of people ask about is, well, can I have a database for development and a database for production? Currently, that's not possible. We're releasing that in the next couple weeks. So, maybe by the time this podcast comes out, the answer will be yes. Um, okay. So, again, we're multitasking here. So, let's let's check this really quick and then we'll go through the deployment flow. My favorites. Okay. We got these things. It says unnamed location. So, we'll uh we'll make that adjustment. So, we're saying, hey, this is what I see when I go to this page, right? We'll get working on that next. Um, and the great thing about this environment, as I was kind of mentioning, we're going to have is that, you know, we're going to have those database features, as I mentioned, is that I can take a snapshot of what I just built and deploy it live to the internet. So this preview link is temporary, but if we want to make that permanent, we go to the deploy tab. Again, this is where you could see, you know, maybe a little bit of scary stuff if you don't know what these things mean. We're going to kind of select the best configuration for you. So, we're not going to worry about that too much right now. But if you want to go back and understand more about these things, you can kind of go back and start to dig into them. But what we're going to do here is uh we'll call it kid-friendly maps. We'll shorten that a little bit. And we're pulling in all of our different secrets from our app as well as the database. And we'll note that we can also run a pre-eployment scan. So if you're concerned about security issues, we released this last week. We have our security scanner. So clicking that button is going to run a scan on our environment to make sure that um it's not secure or it's secure rather. And so what we found actually were some user controlled data input methods in our front end uh that could be potentially vulnerable. So we could actually do is ask agent. Let's make sure agent's done. It says it it says it fixed the favorites. I can get easily distracted. So like I have to make sure I don't get go down a rabbit hole. It doesn't look like it did that. But we're going to table that for later and we're gonna ask agent to fix these security vulnerabilities. So what you see from our security scanner is that we're passing that information to agent and we're saying, "Hey, this component has some issues. Can you fix that for us?" Yeah, this is a great feature, man. This is great. Yeah, man. I think this every app should have this. And and the the most important part I want to emphasize this is like really scanning over your code for real issues. Um, you know, the thing about AI generated code, uh, is we're going to get to a point where we just build these in, you know, but it's almost impossible to make sure that everything, um, is 100% secure and that's why we added this check. Uh, so we're kind of fixing them now and we're going to move more towards a framework where we proactively build without these these um these errors. But if you know if agent's able to catch it, just imagine all the AI generated code that's getting run written and run elsewhere where these haven't been haven't been found. You should just spin this out as a separate product for all the other AI coding tools that exactly this is like required. This is like P0 for all the coding tools. We fixed it, right? And you know, shout out to our partners at Sam GRP for helping us with this one. Um, but what we just did was fix these these security issues. Uh, and so you know, just like that, we patched it. The other thing I was, you know, the other it encompasses a broad range of issues. So like the demo I had I think we can skip because it caught a few other issues is like you can paste in a SQL injection vulnerability in your app and it will detect that as well. But we fixed our security issues. Let's just click deploy again. What's going to happen here is that we're taking a snapshot of our app as it exists right now and we're pushing we're publishing it live to the internet. So, in a couple minutes, that's that'll be out. And then what we can do is come back over here typically and I'll be like, okay, well, like I now have my defunct favorites page. That's like a little unnamed location is a little depressing. Let's see if we can figure out what's going on here. So, we're getting the favorites. What we can do here is we have our element selector. So, I'm going to select this div and or this card title and I'm going to say this still says unnamed uh location. Um, and so we're passing additional context. The element selector is hopefully going to help agent debug the fact that this should not say unload unnamed location. Also kind of nice is that we get a little notes um, you know, functionality in here. So like maybe we want to uh save some notes. Yeah, that's great. You didn't didn't ask for that. You just Yeah. Yeah. Okay. So like look at this. Um, this is working as designed. There's no name available for a location. That's interesting. Well, what's going on on our uh favorites um thing here? Looks like what are we storing? Interesting. It looks like right we might be pulling in uh either we're not one storing the data in the database in the first place. Um or number two uh we're trying to access what agent just said is it's looking for favorite.place.name. I don't actually see a place column in the database. So like there might be an error uh sort of in our implementation. But we you can see both the favorites are in OSM places. So what I'll do for agent also is I'll say I see the favorites table favorites table favorites table and the OSM places table but the name is in OSM places. It looks like you're not pulling it through. I I think may maybe another good best practice here is like before you actually build database maybe just like explore with it a few times what the data table should look look like and like give some fe feedback that might help too. Yeah. um you know like data structures and data you know that is its own profession right you know like it's it's it's hard to change but like there are entire you know data architects is a job of people that just design databases so I don't want to trivialize that especially as you start building out like really complicated applications um it can be very easy to create confusing interfaces that is another place though where as you build you actually learn um the way you want your data structure to to to live or look. And so, you know, maybe I build this app out and I'm like, man, I think we really messed up the architecture. That's where I would go back. I would start uh changing the schema, maybe trying some new things out. That's vibe coding, right? And um it looks like the thing deployed, man. You want to check it out? Yeah, let's take a look. Uh thanks for catching that. So, we have our link here. What we should see is the exact same thing. So, we're loading all those places. Um I can come up here again. It'll be a new login. Uh I can log into my application kid-friendly maps.repit.app and I see my saved because we're using the same data uh database. I see my saved location with my favorites and and of course uh the O also supports like Google login, you know, just an email login too, right? Yeah. Yeah. Yeah. That's so um what I can do here is well I don't want to log out of replet and I think I'm sharing uh I would I want to show you kind of um maybe what this login screen looks like. Um, but you can configure your app icon here. You can also choose login providers. What's going on here? A lot of people ask this question, so this is good to talk about is we're creating if you don't have one, a replet account for the user, unsubscribing them from all marketing materials, so you won't get like annoying emails. If you have users for your apps, don't worry about it. Unless they want to learn about Replet, mostly because I'm sending those emails, so I don't I don't really think they're annoying, but you know, uh, I get it. Um, so we're using all of our infrastructure to create accounts for these users, but then passing that through to your application. So out of the box, you get all the benefits of our authentication infrastructure. Um, which is actually pretty useful as it would turn out because O is really hard. So we want to save you the hassle of building out that O product and make it as easy as possible for you to build. That's awesome. So um, I think we got like five minutes left and it's good that you build a full app that mo mostly works. I think I'll use it this weekend. I'm I'm I'm glad they didn't call it kid-friendly maps Matt Palmer because that that would kind of weird. So, you know, I was like this whole demo I was like, please don't make anything like weird with my name and like, you know, kid-friendly or whatever. So, uh we're doing our best. But, uh I I guess let me ask you one last question, man. Um well, let me ask you two questions. One is like where do you think this vibe coding stuff is going to go? because we're seeing like uh OpenAI launch codeex. Do you think the stuff is going to become more async like you just kind of like tell do stuff and you just kind of go away for a while and then come back or how do you think this thing will evolve? Yeah, I mean that's a complicated question, right? Um yeah, to your point we have codeex, we have cloud code, we have all these other tools those are targeted more at devs, right? What I just showed you today is more for prototyping internal tools uh maybe less technical users, but it does seem like we're moving to that async um that async model. And here's like my theory about that, right? Every uh you know, as time passes, the building blocks that AI can write reliably get bigger, right? So it used to be tab autocomplete. Everybody was like, "Oh man, AI can tab autocomplete. This is crazy." Like a year ago, right? And then it was like AI can write functions. And now we're getting to the point with agents. AI can write entire applications. Now to your to what you just saw, there was a lot of human in the loop, a lot of manual intervention that was required, but that's less than it was five or six months ago. And so the amount of time that AI can work uninterrupted is increasing exponentially. You know, it used to be 5 seconds, now it's 10 minutes, 15 minutes. And so what I think we're going to see is this human in the loop kind of pair programmer model where I'm watching AI, I'm supervising, and then it'll say, "Hey, Matt, I need I need help with this thing." And then I come in and I debug and I help it get around an issue or I give it an architectural decision or make a change to the plan that I had. Um, and that's what I've seen. That's how we've seen things develop. Seems like that's the way um AI is moving. Yeah. I mean the ultimate vibe coding is like I watch some Netflix and then I get notification on my phone and then give them some input and then keep going. You know that's one day. Yeah. There you go. And and and uh you actually didn't cover like you had like a general tip that I really like for vibe coding which is you know the core themes of vibe coding include agency, curiosity and courage. So why don't we why don't we end on that man? like um what do those three things mean to you and why do you think that's really important? Yeah, you know a lot of people ask like what makes a successful vibe coder like how do I get good at this thing? Um you know it boils down to I think the first thing agency having sort of uh the motivation to take action and the motivation to say this thing doesn't work and I'm going to figure out why and I'm going to make it work. You know, in the same way that I kind of used this analogy earlier, if you have a Google spreadsheet in front of you, like it's just a blank canvas. And a lot of times spreadsheets break. They're actually really annoying. I've spent most of my career trying to spend less time in spreadsheets. But they're also really cool and really powerful. So writing code, being an engineer, being someone who builds stuff. It's the same thing as being a product builder. You have to be willing to take action without someone feeding you, you know, sort of like what to do. And you know, with AI, with agent, we get this blank canvas. We can create whatever we want. That can be intimidating, but it means we have to come up with what we want to build. We have to define the requirements and then we have to go tackle those problems that pop up. You know, we have to have uh I think courage. The courage to fail, the courage to start over, the courage to again feel like, oh, I just spent two hours and I didn't actually create anything that worked. And that's really like kind of embarrassing for me. But you know what? I'm going to roll up my sleeves and figure out how to do it the right way and I'm going to try again. Um, and I'm going to learn about the tools. And, you know, that's part of being a professional and part of being a builder. Uh, and I think, you know, that courage ties directly into curiosity of saying, well, how do I make this product better? And a lot of these skills are the same skills that you have if you're a good PM, good designer, good engineer, all of these things. Um, and I think that also ties into agency. It's good to hear that from you because, you know, you're like head of the rail at Rapid. And I feel like a lot of people like who maybe are not engineers just take themselves out of the game. They think like, "Oh, I can't do this. This is too hard for me." And just don't. And now and now I think I want people to realize that you have all these like, you know, you have all these AI tools that will actually be a co-pilot with you will help you through these steps, you know? So like you shouldn't give up. Just keep trying. Yeah. Yeah. And you know, maybe in your own life you've seen this where you knew somebody and they would always say, "Well, I'm bad at math." And so they never got good at math, you know? And it's like if you tell yourself that, well, yeah, no, you're you're not going to try and you're not going to put in the effort to learn it. And you know, my belief I'm a really optimistic guy. I think anybody can do what I'm doing today. Um, you know, it might take a little while. It might take some some trial and error, but I think you all can get there. And, uh, to your point, Peter, some of these projects I used to say, oh, well, like I can get to that with a weekend or in two weeks or like whatever. I just don't have the time. Today, you can get to it like in a morning or in an hour. Figure it out and get a lot of really cool stuff done. Awesome, dude. So, so like where can people find you online? Is it just like repetit.com or Yeah, me specifically. I'm big on X. I love X. you know, you can follow along with me there. I'm also on LinkedIn and I have a personal YouTube channel where I put out videos all the time. I'll give those links to Peter. Uh I'll give it to you well to share in the in the footnotes, right? Um and then all of the Replet content comes uh from the Replet YouTube channel on replet.com. I send out a lot of emails. I send out, you know, uh kind of monthly recap uh some user showcases for good apps people have built. So, if you're into Replet, you can follow along with those there as well. Okay. Thanks so much, Matt. This is awesome. I'm going to play with this app uh myself and try to build it myself. Amazing. Yeah. Thank you.

What is vibe coding?
Last Updated: 12/04/2025

Vibe coding is an emerging software development practice that uses artificial intelligence (AI) to generate functional code from natural language prompts, accelerating development, and making app building more accessible, especially for those with limited programming experience.

The term, coined by AI researcher Andrej Karpathy in early 2025, describes a workflow where the primary role shifts from writing code line-by-line to guiding an AI assistant to generate, refine, and debug an application through a more conversational process. This frees you up to think about the big picture, or the main goal of your app, while the AI handles writing the actual code.

In practice, vibe coding is generally applied in two main ways:

"Pure" vibe coding: In its most exploratory form, a user might fully trust the AI's output to work as intended. As Karpathy framed it, this is akin to "forgetting that the code even exists," making it best suited for rapid ideation or what he called "throwaway weekend projects," where speed is the primary goal.
Responsible AI-assisted development: This is the practical and professional application of the concept. In this model, AI tools act as a powerful collaborator or "pair programmer." The user guides the AI but then reviews, tests, and understands the code it generates, taking full ownership of the final product.
Understanding how the vibe coding process works
Vibe coding operates on two levels: the low-level iterative loop of refining code, and the high-level lifecycle of building and deploying a full application.

The code-level workflow
This is the tight, conversational loop you use to create and perfect a specific piece of code.

Describe the goal: You start with a high-level prompt in plain language. For example: "Create a Python function that reads a CSV file."
AI generates code: The AI assistant interprets your request and produces the initial code.
Execute and observe: You run the generated code to see if it works as intended.
Provide feedback and refine: If the output isnt quite right or an error occurs, you provide new instructions, like, "That works, but add error handling for when the file is not found."
Repeat: This loop of describing, generating, testing, and refining continues until the code is complete.
The application lifecycle
This is the broader process of taking a high-level idea from concept to a deployed application.

Ideation: You describe the entire application you want in a single, high-level prompt in tools like Google AI Studio or Firebase Studio.
Generation: The AI generates the initial version of the full application, including the UI, backend logic, and file structure.
Iterative refinement: You test the application and use follow-up prompts to add new features or change existing ones.
Testing and validation: A human expert reviews the application for security, quality, and correctness.
Deployment: With a final prompt or a single click, you deploy the application to a scalable platform like Cloud Run.
Vibe coding versus traditional programming
With traditional programming, you focus on the details of implementation, manually writing the specific commands, keywords, and punctuation a language requires. Vibe coding lets you focus on the desired outcome instead, describing your goal in plain language, like "create a user login form," while the AI handles the actual code.

Heres a comparison:

Feature

Traditional programming

Vibe coding

Code Creation

Manual coding line by line

AI-generated from natural language prompts



Developer or user role

Architect, implementer, debugger

Prompter, guide, tester, refiner

Coding expertise required

Higher (knowledge of programming languages and syntax)

Lower (understanding of the desired functionality)

Primary input

Precise code

Natural language prompts and feedback

Development speed

Generally slower, methodical

Potentially faster, particularly for prototyping simpler tasks

Error handling

Manual debugging based on code comprehension

Refinement through conversational feedback

Learning curve

Often steep

Potentially lower barrier to entry

Code maintainability

Relies on code quality, developer skill, and established practices

Can depend heavily on AI output quality and user review

Getting started: Choosing your vibe coding tool
Google Cloud offers several tools for vibe coding. Choosing which tool you use should depend on your goal, and not necessarily your job title. A developer might use AI Studio for a quick prototype, an enthusiast might build a full application in Firebase Studio, and a data scientist might use Gemini Code Assist to write a script.

Once you are done prototyping, you deploy to Cloud Run, (for AI Studio and Firebase Studio), and can iterate from there using source code editing or go back to your vibe coding tool.

Use this guide to find the best tool for the task at hand.

Tool

Starting point

Skill level

Coding approach

Key feature

Google AI Studio

An idea you want to see, fast.

Beginner. No coding experience needed.

No-Code / Low-Code

Single-prompt app generation and one-click deployment. The fastest path from concept to a live, sharable application.

Firebase Studio

A new, full-stack application.

Beginner to intermediate. You can start with no code, but experience helps with customization.

Low-Code / No-Code

Full-stack generation with an integrated Firebase backend. Easily add a database, user authentication, and more.

Gemini Code Assist

An existing project or file.

Intermediate to advanced. Designed for users with professional coding experience.

Low-Code / AI-assisted

In-editor assistance. It generates, explains, and tests code directly within your existing IDE workflow

How to vibe code with Google AI Studio
AI Studio is the quickest way to go from an idea to a live, shareable web app, often with a single prompt. It's perfect for rapid prototyping and building simple, generative AI applications.

Step 1: Describe what you want to build in your prompt
To get started, go to Build in AI Studio. In the main prompt area, simply describe the application you want to create. Start with a fun, creative idea, and then simply run the prompt. Once you run the prompt, youll see AI Studio generate the necessary code and files, with a live preview of your app appearing on the right-hand side.

Example prompt: "Create a 'startup name generator' app. It needs a text box where I can enter an industry, and a button. When I click the button, it shows a list of 10 creative names."

Step 2: Refine the app
Now that you have a live preview, you can use the chat interface to refine its look and functionality with follow-up prompts. You could add features, change visual elements, and more.

Example prompt: "Make the background a dark gray and use a bright green for the title and button to give it a 'techy' feel."

Step 3: Deploy to Cloud Run to share
Once youre happy with the result, you can deploy your app directly to the web. Simply click the "Deploy to Cloud Run" button on the right-hand side menu, above your app preview. AI Studio will publish your app to a public URL, making it ready to share with your team or friends.

How to vibe code with Firebase Studio
Firebase Studio is a powerful, web-based environment for building production-ready applications, especially those that need a robust backend with features like user authentication or a database.

Step 1: Describe your full application or vision in your prompt
To get started, open Firebase Studio and describe the complete application you want to build in the prompt area. You can describe a robust, multi-page application from the very beginning. 

Example prompt: Create a simple recipe-sharing application. It needs user accounts so people can sign up and log in. Once logged in, a user should be able to submit a new recipe with a title, ingredients, and instructions. All the submitted recipes should be displayed on the homepage.
Step 2: Review and refine the app blueprint
After submitting your initial prompt, Firebase Studio generates an app blueprint for you to review. This blueprint is a detailed plan outlining the features, style guidelines, and technology stack the AI intends to use.

Here, you can provide feedback to refine the blueprint, ensuring the initial code generation is closer to what you have in mind. Making changes to the plan at this stage is much easier than editing the final code, helping you get to your desired state faster.

Example prompt: This blueprint looks great, but let's remove the 'AI Meal Planner' feature for now and add a 'Favorites' button to the recipe display.
Step 3: Generate the prototype
When you're happy with the blueprint, go ahead and click the "Prototype this App" button. Firebase Studio will then generate a working prototype based on your approved plan. After a moment, a live, interactive preview of your new app will appear.

Step 4: Make edits to your live prototype
With your interactive prototype running in the preview panel, you can continue the conversation to make edits. For example, ask for visual changes, add or change features, or even introduce new logic to your application.

Example prompt: Let's make that heart icon functional. When a signed-in user clicks on it, save the recipe to a 'favorites' list in their user profile in the database. Also, create a new 'My Favorites' page that only displays the recipes that the current user has saved.
Step 5: Deploy your application
When your application is ready, you can deploy it directly from the environment. To do so, simply click "Publish" in the top right-hand corner. Firebase Studio handles the entire deployment process, publishing your app to a public URL using Cloud Run. Because it's built for production, your application is ready to scale and handle traffic from day one.

How to vibe code with Gemini Code Assist
Gemini Code Assist acts as an AI pair programmer directly within your existing code editor (like VS Code or JetBrains). Its best used for helping professional developers work faster and more efficiently directly in their IDE, and on existing projects.

Step 1: Generate code within a file
To get started, open a project file in your IDE. Instead of writing code manually, you can use the Gemini chat window or an in-line prompt to describe the function or code block you need. The AI will generate the code and insert it directly into your file.

Example prompt: "Write a Python function that takes a filename as input. It should use the pandas library to read a CSV file and return a list of all the values from the 'email' column."
Step 2: Refine and improve existing code
Highlight the code you just created (or any block of existing code) and use follow-up prompts to modify or improve it. This is perfect for adding new features, adding error handling, improving performance, or changing logic without having to manually refactor.

Example prompts: "That function is useful. Now, modify it to accept an optional 'domain_filter' parameter. If a domain is provided, the function should only return email addresses that match that specific domain."
"That's a good start, but it will crash if the user doesn't have permissions to read that file. Can you add error handling for a PermissionError?"
Step 3: Generate tests to complete the feature
To ensure your code is production-quality, you can ask Gemini to generate unit tests. This automates a crucial but often time-consuming part of app development.

Example prompt: "Write unit tests for this function using pytest. I need one test for the successful case that returns all emails, another test that filters for a specific domain, and a third test to handle a FileNotFoundError."
Build from idea to application, faster
Vibe coding is more than just a new technique. Its helping shift how we create software. It lowers the barrier to entry for new creators and acts as a powerful force multiplier for experienced developers, allowing everyone to focus more on creative problem-solving and less on manual implementation.

Related Google Cloud products and services
AI studio
Google AI Studio
A web-based tool that lets you experiment with generative AI models and develop prompts for a variety of creative uses
firebase studio logo
Firebase Studio
An AI-powered platform for building and deploying web applications from your prompts.
Gemini logo
Gemini Code Assist
AI coding partner in your IDE for smart code completion, generation, and chat. Helps you code faster, solve problems, and stay in your creative flow.
Vertex AI logo
Vertex AI
Unified ML platform to easily build, deploy, and manage AI models. Experiment rapidly with AutoML, pre-trained APIs, and generative AI tools.
Cloud Run icon
Cloud Run
Serverless platform to deploy containerized apps instantly. Auto-scales (even to zero) for fast iteration of web apps and APIs with low overhead.


So I have been using Cursor for more than 6 months now and I find it a very helpful and very strong tool if used correctly and thoughtfully. Through these 6 months and with a lot of fun projects personal and some production-level projects and after more than 2500+ prompts, I learned a lot of tips and tricks that make the development process much easier and faster and makes and help you vibe without so much pain when the codebase gets bigger and I wanted to make a guide for anyone who is new to this and want literally everything in one post and refer to it whenever need any guidance on what to do!:

1. Define Your Vision Clearly
Start with a strong, detailed vision of what you want to build and how it should work. If your input is vague or messy, the output will be too. Remember: garbage in, garbage out. Take time to think through your idea from both a product and user perspective. Use tools like Gemini 2.5 Pro in Google AI Studio to help structure your thoughts, outline the product goals, and map out how to bring your vision to life. The clearer your plan, the smoother the execution.

2. Plan Your UI/UX First

Before you start building, take time to carefully plan your UI. Use tools like v0 to help you visualize and experiment with layouts early. Consistency is key. Decide on your design system upfront and stick with it. Create reusable components such as buttons, loading indicators, and other common UI elements right from the start. This will save you tons of time and effort later on You can also use **https://21st.dev/**; it has a ton of components with their AI prompts, you just copy-paste the prompt, it is great!

3. Master Git & GitHub
Git is your best friend. You must know GitHub and Git; it will save you a lot if AI messed things up, you could easily return to an older version. If you did not use Git, your codebase could be destroyed with some wrong changes. You must use it; it makes everything much easier and organized. After finishing a big feature, you must make sure to commit your code. Trust me, this will save you from a lot of disasters in the future!

4. Choose a Popular Tech Stack
Stick to widely-used, well-documented technologies. AI models are trained on public data. The more common the stack, the better the AI can help you write high-quality code.

I personally recommend:

Next.js (for frontend and APIs) + Supabase (for database and authentication) + Tailwind CSS (for styling) + Vercel (for hosting).

This combo is beginner-friendly, fast to develop with, and removes a lot of boilerplate and manual setup.

5. Utilize Cursor Rules
Cursor Rules is your friend. I am still using it and I think it is still the best solution to start solid. You must have very good Cursor Rules with all the tech stack you are using, instructions to the AI model, best practices, patterns, and some things to avoid. You can find a lot of templates here: **https://cursor.directory/**!!

6. Maintain an Instructions Folder
Always have an instructions folder. It should have markdown files. It should be full of docs-example components to provide to the Ai to guide it better or use (or context7 mcp, it has a tons of documentation).

7. Craft Detailed Prompts
Now the building phase starts. You open Cursor and start giving it your prompts. Again, garbage in, garbage out. You must give very good prompts. If you cannot, just go plan with Gemini 2.5 Pro on Google AI Studio; make it make a very good intricate version of your prompt. It should be as detailed as possible; do not leave any room for the AI to guess, you must tell it everything.

8. Break Down Complex Features
Do not give huge prompts like "build me this whole feature." The AI will start to hallucinate and produce shit. You must break down any feature you want to add into phases, especially when you are building a complex feature. Instead of one huge prompt, it should be broken down into 3-5 requests or even more based on your use case.

9. Manage Chat Context Wisely
When the chat gets very big, just open a new one. Trust me, this is the best. The AI context window is limited; if the chat is very big, it will forget everything earlier, it will forget any patterns, design and will start to produce bad outputs. Just start a new chat window then. When you open the new window, just give the AI a brief description about the feature you were working on and mention the files you were working on. Context is very important (more on that is coming..)!

10. Don't Hesitate to Restart/Refine Prompts
When the AI gets it wrong and goes in the wrong way or adding things that you do not want, returning back, changing the prompt, and sending the AI again would be just much better than completing on this shit code because AI will try to save its mistakes and will probably introduce new ones. So just return, refine the prompt, and send it again!

11. Provide Precise Context
Providing the right context is the most important thing, especially when your codebase gets bigger. Mentioning the right files that you know the changes will be made to will save a lot of requests and too much time for you and the AI. But you must make sure these files are relevant because too much context can overwhelm the AI too. You must always make sure to mention the right components that will provide the AI with the context it needs.

12. Leverage Existing Components for Consistency
A good trick is that you can mention previously made components to the AI when building new ones. The AI will pick up your patterns fast and will use the same in the new component without so much effort!

13. Iteratively Review Code with AI
After building each feature, you can take the code of the whole feature, copy-paste it to Gemini 2.5 Pro (in Google AI Studio) to check for any security vulnerabilities or bad coding patterns; it has a huge context window. Hence, it actually gives very good insights where you can then input into to Claude in Cursor and tell it to fix these flaws. (Tell Gemini to act as a security expert and spot any flaws. In another chat, tell it so you are an expert (in the tech stack at your tech stack), ask it for any performance issues or bad coding patterns). Yeah, it is very good at spotting them! After getting the insights from Gemini, just copy-paste it into Claude to fix any of them, then send it Gemini again until it tells you everything is 100% ok.

14. Prioritize Security Best Practices
Regarding security, because it causes a lot of backlash, here are security patterns that you must follow to ensure your website is good and has no very bad security flaws (though it won't be 100% because there will be always flaws in any website by anyone!):

Trusting Client Data: Using form/URL input directly.

Fix: Always validate & sanitize on server; escape output.

Secrets in Frontend: API keys/creds in React/Next.js client code.

Fix: Keep secrets server-side only (env vars, ensure .env is in .gitignore).

Weak Authorization: Only checking if logged in, not if allowed to do/see something.

Fix: Server must verify permissions for every action & resource.

Leaky Errors: Showing detailed stack traces/DB errors to users.

Fix: Generic error messages for users; detailed logs for devs.

No Ownership Checks (IDOR): Letting user X access/edit user Y's data via predictable IDs.

Fix: Server must confirm current user owns/can access the specific resource ID.

Ignoring DB-Level Security: Bypassing database features like RLS for fine-grained access.

Fix: Define data access rules directly in your database (e.g., RLS).

Unprotected APIs & Sensitive Data: Missing rate limits; sensitive data unencrypted.

Fix: Rate limit APIs (middleware); encrypt sensitive data at rest; always use HTTPS.

15. Handle Errors Effectively
When you face an error, you have two options:

Either return back and make the AI do what you asked for again, and yeah this actually works sometimes.

If you want to continue, just copy-paste the error from the console and tell the AI to solve it. But if it took more than three requests without solving it, the best thing to do is returning back again, tweaking your prompt, and providing the correct context as I said before. Correct prompt and right context can save sooo much effort and requests.

16. Debug Stubborn Errors Systematically
If there is an error that the AI took so much on and seems never to get it or solve it and started to go on rabbit holes (usually after 3 requests and still did not get it right), just tell Claude to take an overview of the components the error is coming from and list top suspects it thinks are causing the error. And also tell it to add logs and then provide the output of them to it again. This will significantly help it find the problem and it works correctly most of the times!

17. Be Explicit: Prevent Unwanted AI Changes
Claude has this trait of adding, removing, or modifying things you did not ask for. We all hate it and it sucks. Just a simple sentence under every prompt like (Do not fuckin change anything I did not ask for Just do only what I fuckin told you) works very well and it is really effective!

18. Keep a "Common AI Mistakes" File
Always have a file of mistakes that you find Claude doing a lot. Add them all to that file and when adding any new feature, just mention that file. This will prevent it from doing any frustrating repeated mistakes and you from repeating yourself!

I know it does not sound as "vibe coding" anymore and does not sound as easy as all of others describe, but this is actually what you need to do in order to pull off a good project that is useful and usable for a large number of users. These are the most important tips that I learned after using Cursor for more than 6 months and building some projects using it! I hope you found it helpful and if you have any other questions I am happy to help!

Also, if you made it to here you are a legend and serious about this, so congrats bro!

Happy vibing!

A Comprehensive Guide to Vibe Coding Tools
Madhukar Kumar
Madhukar Kumar

Follow
13 min read

Mar 30, 2025
932


26



Press enter or click to view image in full size

If you have been hanging around developers watering holes (X and YouTube), chances are you have come across a new emerging lexicon with words like  cracked, cooked, lock in and variations of vibe coding.
Every time there is a new wave of a trend like this, I often wonder  is there a way to trace a trend back to one moment, one conversation where this may have started and then took on a whole new life?
Maybe not for everything but thanks to most of the conversations now happening in the online world, the provenance of some can be verifiably traced back to the moment something was minted.
This is the story of Vibe Coding  a term first articulated by the prolific thinker  Andrej Karpathy on X.

Press enter or click to view image in full size

Ever since this was posted, the post has been viewed over 4.5 million times, and the ever-expanding plethora of vibe coding tools has become a mini-industry of its own. To be fair, a lot of these existed before this now famous tweet but now with an official category name, there are no dearth of influencers riding the wave of posting and re-posting screenshares of games and other SaaS applications people have been building using vibe coding.
In many ways, I think of vibe coding as an evolution of programming from telling the system how to do something, for example a bubble sort, to telling it what to do. In some cases, as Andej mentioned, it probably does not matter how certain things are made as long as they work.
And therein also lies the challenge if you are an engineer working in a team in a large enterprises where you not building new games or apps every day, rather working on millions of lines of code that have been already written to improve, fix and add features on top of. Here, it does matter how things are made. If vibe coding is about Day 0 experience of building apps, Day 1 is about building upon that code, fixing bugs, adding features and working with other team members.
As a professional dopamine chaser who loves to build things and get a kick out of watching something come to life, I have been using and playing around with all possible vibe coding tools I could get my hands on for a few months now. In this article, I am cataloging those tools as of today to organize my own thoughts and help others who may be interested in getting a high-level overview of this fascinating new universe of coding before diving in.
Before we dive in though, lets break the vibe coding tools under some broad categories of what people are looking to build.
Full Stack App
A full stack app consists of a front-end code (UI), backend (API) calls, database, integration and storage. If you have a business idea and you are looking to sell software or a product this is what you want which means in addition to the list of things above, there are two other important ingredients of full stack apps  Authentication and Payment integration. Finally, once the app is made, you want to deploy it to a server so that users can access them from a URL.
Traditionally, building a full stack app required teams of people and took months, if not years to build. Today, believe if or not, you can build a full stack app in a day with just you sitting in front of a computer.
Lets first look at UI centric AI coding tools that can be used to build full stack apps. Using these tools not only can you generate and immediately view the apps, but you can also click on certain elements in the app and continue asking the AI tool to change specific parts of the UI.

Tempo Labs
Tempo labs is not entirely built for a no-coder but it also has fairly good controls for both low-code and intermediate programmers. With Tempo labs, you can choose the authentication technology and backend at the start of the project and one of its neat feature is that it also generates the Product Requirements Document (PRD) and user flow diagrams along with the code and you can continue to either add new components visually or directly with AI prompts or by exporting the code and using the PRD to iterate on the code with other AI coding tools. The overall user flow diagram is also a very nifty way to visualize your apps user journey in an efficient way.
With Tempo labs you can also create payment integration with Stripe and Polar and enable authentication and database with Supabase or Convex.
More recently, Tempo labs launched a new feature that enables creating a new application from an existing Github repo. However, at the time of writing this article, I could not get this to work for three different NextJS existing applications. I have hope this gets better with time so the tool becomes useful not for just Day 0 apps but also Day 1+ apps.
Press enter or click to view image in full size

2. Bolt.new / Bolt.diy
Similar to Tempo labs, Bolt.new is a tool created by Stackbliz that enables building an entire full stack app using AI visually. One of its unique features is to directly import designs from a Figma account and convert those into code (application)
Stackblitz had introduced the idea of web containers that enable Node to run in the browser and using this feature, which means not only can you use AI prompts to build the app visually, you can also open the entire code base in a Visual Studio IDE running a browser (Stackblitz). This enables making changes to the code directly when you need to and you can add additional VS code extensions to keep your programming experience consistent across multiple computing environments.

Press enter or click to view image in full size

Bolt.new also has integration with Supabase that lets you create both authentication as well standard backend database CRUD operations but at the time of writing this article I did not see an out-of-box integration with a payment system like Polar or Stripe. Finally, they recently added the ability to import a project from Github which means you can bring in an existing application and continue to work in Stackblitz. However, the apps you import into Stackblitz is not something you can use in Bolt.new but this would be a good feature if the creators add in the future.

3. Lovable.dev
Probably the most user friendly for non-coders and low coders, the next full stack AI tool to look at is Lovable.dev. It has very similar features to both Bolt.new and Tempo labs. You can build and deploy an entire app using the AI prompt and one Lovables unique feature is to be able to select parts of an app/webpage and request the AI to make very targeted and specific changes. It is also integrated to Supabase for both authentication and database CRUD operations and you can connect your Github repo to the app. This means you can work on your code base outside of Lovable and when you do a push to the main branch, Lovable does an automatic pull so you can go back and forth from either writing code in your code editor or using Lovables visual UI prompts.

Press enter or click to view image in full size

Others  There are a few other tools just like the three above but in order to not make this article not too unwieldy I will just mention these but not go into details since they are very similar to all the three above:
Replit  Replit agent allows you to build apps using AI prompts and directly deploy to a production server within Replit in a single interface.
Base44  This is another tool very similar to the ones above but has more bare bones starter template and seems like it is geared more towards more advanced developers.
Now that we have looked at the full stack visual tools, lets look at some of the code editor tools that have become very popular in making applications. Within this category itself there are either VS code forks or extensions that live within VS code. Personally, I prefer VS code extensions because I can switch tools as needed without changing my experience and I am not locked into one tool or one way of doing things for the same code base.

VS Code Forks
Cursor  One of the early starters in the vibe coding space, Cursor first started as a way to chat and get code completions and changes. A few weeks later they launched Composer feature that allowed users to directly tell the agents to make the code changes directly and since then this entire space and this tool has evolved significantly. More recently, Cursor also added support for MCP servers so that you can also use it to call other pre-built tools and services to help build an entire app using just AI prompts.
What I dont like about Cursor is that it has become very complicated with different and often unnecessary bells and whistles and as the codebase becomes bigger and complicated, you now have to maintain rules files and context files to constantly guide Cursor to not mess up and do things that are either not needed or repeat mistakes that were already fixed.
Press enter or click to view image in full size

2. Windsurf  Similar to Cursor Windsuft is another VS Code fork and has very similar if not identical features. In terms of user experience, Windsurf comes across better than Cursor but the results you get from the AI models are usually similar given this also does not have constant context of the code base as it continues to grow. Windsurf also has support for MCP servers. One of the new features that Windsurf added which is not currently in Cursor is the ability to preview the app directly in the code editor. This is something, however, I think others will also add to their tools.

Press enter or click to view image in full size

3. Trae  Speaking of preview or web view, yet another VS code fork is from the makers of Tiktok called Trae. It has better user experience and a very generous free tier, but it lacks MCP integration features which means you cannot really use only this tool for your entire application build. Not a surprise it also lacks robust context management which means it is not very useful if you are trying to work on a existing code base or if you are working with multiple team members.

Press enter or click to view image in full size

Now lets look at the last category (my favorite)  VS Code extensions. These are AI tools that you can bolt on to your existing coding workflow and add/remove as needed given the fast pace of changes in this area.

VS Code Extensions
Amp  In May, Amp, a fully autonomous coding agent was released both as a VS code extension and as a CLI. What is different about Amp is that it is built for teams and especially aimed at engineers who see themselves as quality-obsessed perfectionists. Amp is pay-per-token model so it does not restrict token or tools usage which means the model goes about doing things the way it is designed to resulting in better outcomes. Users on X have been posting positively about it since it was released. It also has a teams shareable threads feature that allows team members to learn from each others conversation with the agent. Finally, given that this is also available as a CLI, if you are working on deterministic workflows on Linux, for example, you can now pipe in NLP to Amp and build some interesting automation workflows.
Press enter or click to view image in full size

2. Augment

Get Madhukar Kumars stories in your inbox
Join Medium for free to get updates from this writer.

Enter your email
Subscribe
Augment is a VS Code extension that integrates with existing repositories by first indexing and then analyzing the codebase. If you are on a free tier it tells you that the tool will use your codebase for their own training which to me is a put off. However, if you are ok with that then once the codebase has been indexed you can use Augment to primarily either ask questions about your code or get code completions. At the time of writing this, Augment did not have an agentic mode nor did it support MCPs.

Press enter or click to view image in full size

3. Continue
Continue is similar to Cursor in that it has both a chat mode and an agent mode and it has MCP servers integration. It also has a feature to index your entire codebase but it still requires users to mention files and folders in order to get the right context. What I also like about Continue is that it has MCP integration as well so I can bring in my tools like Brave search and Firecrawl to build additional context.

Press enter or click to view image in full size

4. Cline
Cline also has similar if not identical features to Cursor and Windsurf but in a VS Code extension vs an entire VS Code fork. Clines agentic features focus on task automation, allowing developers to describe complex tasks that the tool then breaks down and implements step-by-step. For UI modifications, Cline can analyze component structure and suggest changes that maintain visual consistency. What distinguishes Cline is its specialized code prediction feature that anticipates what developers might need next based on coding patterns and current context. Having said that I found Cline to be very token hungry which makes it expensive especially if you try to run it in a YOLO (you only live once) mode.

Press enter or click to view image in full size

5. Sourcegraph
Probably the best tool for professional grade developers looking to work on existing code bases and multiple team members is Sourcegraph. It offers enterprise-grade repository integration with support for multiple version control systems and large-scale codebases. This means you can connect hundreds of repositories and not only search across them but look for insights and do batch changes like refactoring or updating a library or security fixes etc. Recently it also added a VS code extension  Cody that is integrated with Sourcegraph and you can use it to chat in addition to also doing code completion based on its powerful search and context management features.
What makes Sourcegraph stand out is its cross-repository awareness that allows developers to understand how code is used and shared across multiple projects, making it especially valuable for large organizations.

Others  There are two other tools in this space that are similar that are worth mentioning

Press enter or click to view image in full size

Fynix  Fynix distinguishes itself with its code evolution tracking feature that helps understand how code has changed over time, making it easier to plan and implement consistent modifications.
Pythagora
I found Pythagoras use interface hard to get used to but having said that it is great if you are building a brand-new Node based app. It was not very helpful when I tried it against an existing codebase.
I also found the overall user experience to be extremely confusing.
Press enter or click to view image in full size

Finally, lets look at the last category of standalone tools.

Standalone Tools
Devin  Cognition Labs
Devin connects to existing repositories through a combination of Git integration and specialized code understanding capabilities. Its codebase search and context features are good, with the ability to understand complex project structures and dependencies across large codebases. Devins agentic capabilities are its primary strength, allowing it to function as an autonomous developer that can plan, implement, debug, and test code with minimal human intervention. What is different and a little strange about Devin is that you can interface with it only through Slack which means if you are a one-person company, you also need to get Slack.

2. Aider
Meant for more advanced users, Aider, a terminal based tool provides straightforward repository integration through command-line interfaces and Git, making it easy to incorporate into existing development workflows. Its codebase context capabilities focus on understanding local code structure and maintaining consistency with existing patterns. Aiders agentic capabilities enable it to act as a pair programmer, implementing requested changes while maintaining awareness of the broader codebase context. Its UI modification capabilities are more limited, focusing primarily on functional components rather than design systems. Aiders distinguishing feature is its conversation-driven development approach, where developers describe changes in natural language and Aider implements them while maintaining a conversational interface for clarifications and revisions.

3. Claude Code

Press enter or click to view image in full size

Launched a few days before I started writing this article, Anthropic released Claude Code which is primarily a terminal-based tool. What is unique about Claude Code is that it first reads and understands the code base which is then used for the remainder of the session to chat and make changes. It also persists this memory in a markdown file that can be modified and used for future sessions.
Claude Codes agentic capabilities focus on task automation and assistance rather than fully autonomous development. I should mention though that Claude Code is by far the most expensive tool and is a token guzzler. For a simple set of changes that I tested against I saw a token usage of about $5 in a couple of hours. Since this is an Anthropic released tool, I should also mention that it only supports Claude as a model for now.

Conclusion
In this article we saw the different categories of AI tools that can be used for vibe coding and each has its pros and cons. The reality is that as of today you cannot just rely on one tool to build and maintain your entire application. I also found most of the tools only geared for Day 0 (new app building) use cases and hopeful for tools like Sourcegraph, Claude Code and Continue to get better at doing Day 1+ coding tasks.

