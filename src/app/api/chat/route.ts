export const dynamic = 'force-dynamic'
import OpenAI from "openai"
import { NextRequest, NextResponse } from "next/server"
import { getUserFromRequest } from "@/lib/server-auth"

import { rateLimit } from "@/lib/rate-limit";

// ğŸ›¡ï¸ Rate limiting
const limiter = rateLimit({
    interval: 60 * 1000, // 1 minute
    uniqueTokenPerInterval: 500, // Max users per interval
});

async function checkRateLimit(userId: string) {
    try {
        await limiter.check(null, 10, userId); // 10 requests per minute
        return { allowed: true };
    } catch {
        return { allowed: false };
    }
}

// Lazy initialization to avoid build-time errors
function getClient() {
    return new OpenAI({
        apiKey: process.env.GROQ_API_KEY,
        baseURL: "https://api.groq.com/openai/v1",
    })
}

export async function POST(request: NextRequest) {
    try {
        // ğŸ›¡ï¸ AUTHENTICATION REQUIRED
        const user = await getUserFromRequest(request);
        if (!user) {
            return NextResponse.json(
                { error: "áƒáƒ•áƒ¢áƒáƒ áƒ˜áƒ–áƒáƒªáƒ˜áƒ áƒáƒ£áƒªáƒ˜áƒšáƒ”áƒ‘áƒ”áƒšáƒ˜áƒ" },
                { status: 401 }
            );
        }

        // ğŸ›¡ï¸ RATE LIMITING
        const { allowed } = await checkRateLimit(user._id.toString());
        if (!allowed) {
            return NextResponse.json(
                { error: "áƒ«áƒáƒšáƒ˜áƒáƒœ áƒ‘áƒ”áƒ•áƒ áƒ˜ áƒ›áƒáƒ—áƒ®áƒáƒ•áƒœáƒ. áƒ’áƒ—áƒ®áƒáƒ•áƒ— áƒ“áƒáƒ”áƒšáƒáƒ“áƒáƒ— 1 áƒ¬áƒ£áƒ—áƒ¡." },
                { status: 429 }
            );
        }

        const client = getClient()
        const { message, history, botId, masterPrompt } = await request.json()

        if (!message) {
            return NextResponse.json({ error: "Message is required" }, { status: 400 })
        }

        // ğŸ›¡ï¸ Validate and sanitize masterPrompt
        let systemPrompt = "áƒ¨áƒ”áƒœ áƒ®áƒáƒ  AI áƒáƒ¡áƒ˜áƒ¡áƒ¢áƒ”áƒœáƒ¢áƒ˜. áƒáƒáƒ¡áƒ£áƒ®áƒáƒ‘ áƒ¥áƒáƒ áƒ—áƒ£áƒšáƒáƒ“ áƒ“áƒ áƒ”áƒ®áƒ›áƒáƒ áƒ”áƒ‘áƒ˜ áƒ›áƒáƒ›áƒ®áƒ›áƒáƒ áƒ”áƒ‘áƒ”áƒšáƒ¡.";

        if (masterPrompt) {
            // Limit prompt length to prevent abuse
            if (masterPrompt.length > 2000) {
                return NextResponse.json(
                    { error: "Master prompt áƒ«áƒáƒšáƒ˜áƒáƒœ áƒ’áƒ áƒ«áƒ”áƒšáƒ˜áƒ" },
                    { status: 400 }
                );
            }
            systemPrompt = masterPrompt;
        }

        // Build conversation history for context
        const messages: { role: "system" | "user" | "assistant"; content: string }[] = [
            {
                role: "system",
                content: systemPrompt
            }
        ]

        // Add conversation history if provided
        if (history && Array.isArray(history)) {
            for (const msg of history.slice(-10)) {
                if (msg.role === "user" || msg.role === "assistant") {
                    messages.push({
                        role: msg.role,
                        content: msg.content
                    })
                }
            }
        }

        // Add current message
        messages.push({
            role: "user",
            content: message
        })

        const response = await client.chat.completions.create({
            model: "llama-3.3-70b-versatile",
            messages,
            temperature: 0.7,
            max_tokens: 500,
        })

        const content = response.choices[0]?.message?.content || "áƒ‘áƒáƒ“áƒ˜áƒ¨áƒ˜, áƒ“áƒ áƒáƒ”áƒ‘áƒ˜áƒ— áƒ•áƒ”áƒ  áƒ•áƒáƒáƒ¡áƒ£áƒ®áƒáƒ‘. áƒ¡áƒªáƒáƒ“áƒ”áƒ— áƒ—áƒáƒ•áƒ˜áƒ“áƒáƒœ! ğŸ™"

        return NextResponse.json({ response: content })

    } catch (error) {
        console.error("Chat API error:", error)
        return NextResponse.json(
            { error: "Failed to generate response" },
            { status: 500 }
        )
    }
}

